{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Synchronous PPO with PyBullet Ant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Packaged loaded. TF version is [1.14.0].\n"
     ]
    }
   ],
   "source": [
    "import datetime,gym,os,pybullet_envs,time,os,psutil,ray\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from util import gpu_sess,suppress_tf_warning\n",
    "from ppo import PPOBuffer,create_ppo_model,create_ppo_graph,update_ppo,\\\n",
    "    save_ppo_model,restore_ppo_model\n",
    "np.set_printoptions(precision=2)\n",
    "suppress_tf_warning() # suppress warning \n",
    "gym.logger.set_level(40) # gym logger \n",
    "print (\"Packaged loaded. TF version is [%s].\"%(tf.__version__))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rollout Worker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_env():\n",
    "    import pybullet_envs,gym\n",
    "    gym.logger.set_level(40) # gym logger \n",
    "    return gym.make('AntBulletEnv-v0')\n",
    "\n",
    "def get_eval_env():\n",
    "    import pybullet_envs,gym\n",
    "    gym.logger.set_level(40) # gym logger\n",
    "    eval_env = gym.make('AntBulletEnv-v0')\n",
    "    _ = eval_env.render(mode='human') # enable rendering\n",
    "    _ = eval_env.reset()\n",
    "    for _ in range(3): # dummy run for proper rendering \n",
    "        a = eval_env.action_space.sample()\n",
    "        o,r,d,_ = eval_env.step(a)\n",
    "        time.sleep(0.01)\n",
    "    return eval_env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model\n",
    "hdims = [256,256]\n",
    "\n",
    "# Graph\n",
    "clip_ratio = 0.2\n",
    "pi_lr = 3e-4\n",
    "vf_lr = 1e-3\n",
    "epsilon = 1e-2\n",
    "\n",
    "# Buffer\n",
    "steps_per_epoch = 5000\n",
    "gamma = 0.99\n",
    "lam = 0.95\n",
    "\n",
    "# Update\n",
    "train_pi_iters = 100\n",
    "train_v_iters = 100\n",
    "target_kl = 0.01\n",
    "epochs = 1000\n",
    "max_ep_len = 1000\n",
    "\n",
    "# Worker \n",
    "n_cpu = n_workers = 15\n",
    "total_steps,evaluate_every,print_every = 1000,50,10\n",
    "ep_len_rollout = 500\n",
    "batch_size = 4096\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RolloutWorkerClass(object):\n",
    "    \"\"\"\n",
    "    Worker without RAY (for update purposes)\n",
    "    \"\"\"\n",
    "    def __init__(self,seed=1):\n",
    "        self.seed = seed\n",
    "        # Each worker should maintain its own environment\n",
    "        import pybullet_envs,gym\n",
    "        from util import suppress_tf_warning\n",
    "        suppress_tf_warning() # suppress TF warnings\n",
    "        gym.logger.set_level(40) # gym logger \n",
    "        self.env = get_env()\n",
    "        odim,adim = self.env.observation_space.shape[0],self.env.action_space.shape[0]\n",
    "        self.odim = odim\n",
    "        self.adim = adim\n",
    "        # Initialize PPO\n",
    "        self.model,self.sess = create_ppo_model(env=self.env,hdims=hdims,output_actv=tf.nn.tanh)\n",
    "        self.graph = create_ppo_graph(self.model,\n",
    "                                      clip_ratio=clip_ratio,pi_lr=pi_lr,vf_lr=vf_lr,epsilon=epsilon)\n",
    "        # Initialize model \n",
    "        tf.set_random_seed(self.seed)\n",
    "        np.random.seed(self.seed)\n",
    "        self.sess.run(tf.global_variables_initializer())\n",
    "        \n",
    "        # Flag to initialize assign operations for 'set_weights()'\n",
    "        self.FIRST_SET_FLAG = True\n",
    "        \n",
    "    def get_action(self,o,deterministic=False):\n",
    "        act_op = self.model['mu'] if deterministic else self.model['pi']\n",
    "        return self.sess.run(act_op, feed_dict={self.model['o_ph']:o.reshape(1,-1)})[0]\n",
    "    \n",
    "    def get_weights(self):\n",
    "        \"\"\"\n",
    "        Get weights\n",
    "        \"\"\"\n",
    "        weight_vals = self.sess.run(self.model['pi_vars']+self.model['v_vars'])\n",
    "        return weight_vals\n",
    "    \n",
    "    def set_weights(self,weight_vals):\n",
    "        \"\"\"\n",
    "        Set weights without memory leakage\n",
    "        \"\"\"\n",
    "        if self.FIRST_SET_FLAG:\n",
    "            self.FIRST_SET_FLAG = False\n",
    "            self.assign_placeholders = []\n",
    "            self.assign_ops = []\n",
    "            for w_idx,weight_tf_var in enumerate(self.model['pi_vars']+self.model['v_vars']):\n",
    "                a = weight_tf_var\n",
    "                assign_placeholder = tf.placeholder(a.dtype, shape=a.get_shape())\n",
    "                assign_op = a.assign(assign_placeholder)\n",
    "                self.assign_placeholders.append(assign_placeholder)\n",
    "                self.assign_ops.append(assign_op)\n",
    "        for w_idx,weight_tf_var in enumerate(self.model['pi_vars']+self.model['v_vars']):\n",
    "            self.sess.run(self.assign_ops[w_idx],\n",
    "                          {self.assign_placeholders[w_idx]:weight_vals[w_idx]})    \n",
    "    \n",
    "@ray.remote\n",
    "class RayRolloutWorkerClass(object):\n",
    "    \"\"\"\n",
    "    Rollout Worker with RAY\n",
    "    \"\"\"\n",
    "    def __init__(self,worker_id=0,ep_len_rollout=1000):\n",
    "        # Parse\n",
    "        self.worker_id = worker_id\n",
    "        self.ep_len_rollout = ep_len_rollout\n",
    "        # Each worker should maintain its own environment\n",
    "        import pybullet_envs,gym\n",
    "        from util import suppress_tf_warning\n",
    "        suppress_tf_warning() # suppress TF warnings\n",
    "        gym.logger.set_level(40) # gym logger \n",
    "        self.env = get_env()\n",
    "        odim,adim = self.env.observation_space.shape[0],self.env.action_space.shape[0]\n",
    "        self.odim = odim\n",
    "        self.adim = adim\n",
    "        # Replay buffers to pass\n",
    "        self.o_buffer = np.zeros((self.ep_len_rollout,self.odim))\n",
    "        self.a_buffer = np.zeros((self.ep_len_rollout,self.adim))\n",
    "        self.r_buffer = np.zeros((self.ep_len_rollout))\n",
    "        self.v_t_buffer = np.zeros((self.ep_len_rollout))\n",
    "        self.logp_t_buffer = np.zeros((self.ep_len_rollout))\n",
    "        # Create PPO model\n",
    "        self.model,self.sess = create_ppo_model(env=self.env,hdims=hdims,output_actv=tf.nn.tanh)\n",
    "        # Initialize model \n",
    "        self.sess.run(tf.global_variables_initializer())\n",
    "        # Buffer\n",
    "        self.buf = PPOBuffer(odim=self.odim,adim=self.adim,\n",
    "                             size=ep_len_rollout,gamma=gamma,lam=lam)\n",
    "        \n",
    "        # Flag to initialize assign operations for 'set_weights()'\n",
    "        self.FIRST_SET_FLAG = True\n",
    "        \n",
    "        # Flag to initialize rollout\n",
    "        self.FIRST_ROLLOUT_FLAG = True\n",
    "        \n",
    "    def get_action(self,o,deterministic=False):\n",
    "        act_op = self.model['mu'] if deterministic else self.model['pi']\n",
    "        return self.sess.run(act_op, feed_dict={self.model['o_ph']:o.reshape(1,-1)})[0]\n",
    "    \n",
    "    def set_weights(self,weight_vals):\n",
    "        \"\"\"\n",
    "        Set weights without memory leakage\n",
    "        \"\"\"\n",
    "        if self.FIRST_SET_FLAG:\n",
    "            self.FIRST_SET_FLAG = False\n",
    "            self.assign_placeholders = []\n",
    "            self.assign_ops = []\n",
    "            for w_idx,weight_tf_var in enumerate(self.model['pi_vars']+self.model['v_vars']):\n",
    "                a = weight_tf_var\n",
    "                assign_placeholder = tf.placeholder(a.dtype, shape=a.get_shape())\n",
    "                assign_op = a.assign(assign_placeholder)\n",
    "                self.assign_placeholders.append(assign_placeholder)\n",
    "                self.assign_ops.append(assign_op)\n",
    "        for w_idx,weight_tf_var in enumerate(self.model['pi_vars']+self.model['v_vars']):\n",
    "            self.sess.run(self.assign_ops[w_idx],\n",
    "                          {self.assign_placeholders[w_idx]:weight_vals[w_idx]})    \n",
    "        \n",
    "    def rollout(self):\n",
    "        \"\"\"\n",
    "        Rollout\n",
    "        \"\"\"\n",
    "        if self.FIRST_ROLLOUT_FLAG:\n",
    "            self.FIRST_ROLLOUT_FLAG = False\n",
    "            self.o = self.env.reset() # reset environment\n",
    "        # Loop\n",
    "        for t in range(ep_len_rollout):\n",
    "            a,v_t,logp_t = self.sess.run(\n",
    "                self.model['get_action_ops'],feed_dict={self.model['o_ph']:self.o.reshape(1,-1)})\n",
    "            o2, r, d, _ = self.env.step(a[0])\n",
    "            # save and log\n",
    "            self.buf.store(self.o,a,r,v_t,logp_t)\n",
    "            # Update obs (critical!)\n",
    "            self.o = o2\n",
    "            if d:\n",
    "                self.buf.finish_path(last_val=0.0)\n",
    "                self.o = self.env.reset() # reset when done \n",
    "        \n",
    "        last_val = self.sess.run(self.model['v'],\n",
    "                                 feed_dict={self.model['o_ph']:self.o.reshape(1,-1)})\n",
    "        self.buf.finish_path(last_val)\n",
    "        return self.buf.get()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize PyBullet Ant Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment Ready. odim:[28] adim:[8].\n"
     ]
    }
   ],
   "source": [
    "eval_env = get_eval_env()\n",
    "adim,odim = eval_env.action_space.shape[0],eval_env.observation_space.shape[0]\n",
    "print (\"Environment Ready. odim:[%d] adim:[%d].\"%(odim,adim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize Workers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-07-03 03:59:38,528\tWARNING services.py:586 -- setpgrp failed, processes may not be cleaned up properly: [Errno 1] Operation not permitted.\n",
      "2020-07-03 03:59:38,530\tINFO resource_spec.py:212 -- Starting Ray with 4.98 GiB memory available for workers and up to 10.0 GiB for objects. You can adjust these settings with ray.init(memory=<bytes>, object_store_memory=<bytes>).\n",
      "2020-07-03 03:59:38,940\tINFO services.py:1078 -- View the Ray dashboard at \u001b[1m\u001b[32mlocalhost:8266\u001b[39m\u001b[22m\n",
      "2020-07-03 03:59:38,944\tWARNING services.py:1403 -- WARNING: The object store is using /tmp instead of /dev/shm because /dev/shm has only 5898719232 bytes available. This may slow down performance! You may be able to free up space by deleting files in /dev/shm or terminating any running plasma_store_server processes. If you are inside a Docker container, you may need to pass an argument with the flag '--shm-size' to 'docker run'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAY initialized with [15] cpus and [15] workers.\n"
     ]
    }
   ],
   "source": [
    "ray.init(num_cpus=n_cpu,\n",
    "         memory = 5*1024*1024*1024,\n",
    "         object_store_memory = 10*1024*1024*1024,\n",
    "         driver_object_store_memory = 1*1024*1024*1024)\n",
    "tf.reset_default_graph()\n",
    "R = RolloutWorkerClass(seed=0)\n",
    "workers = [RayRolloutWorkerClass.remote(worker_id=i,ep_len_rollout=ep_len_rollout) \n",
    "           for i in range(n_workers)]\n",
    "print (\"RAY initialized with [%d] cpus and [%d] workers.\"%\n",
    "       (n_cpu,n_workers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "time.sleep(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/1000] rollout:[3.0]s pi_iter:[99/100] update:[0.9]s kl:[0.0047] target_kl:[0.0100].\n",
      "   pi_loss:[-0.0079], entropy:[7.3506]\n",
      "[Eval. start] step:[1/1000][0.0%] #step:[0.0e+00] time:[00:00:03] ram:[72.4%].\n",
      "[Evaluate] ep_ret:[5.4077] ep_len:[20]\n",
      "[../data/net/ppo_ant/model.npz] saved.\n",
      "[10/1000] rollout:[1.0]s pi_iter:[99/100] update:[0.7]s kl:[0.0060] target_kl:[0.0100].\n",
      "   pi_loss:[-0.0060], entropy:[6.9988]\n",
      "[20/1000] rollout:[1.0]s pi_iter:[99/100] update:[0.7]s kl:[0.0078] target_kl:[0.0100].\n",
      "   pi_loss:[-0.0027], entropy:[6.7738]\n",
      "[30/1000] rollout:[1.0]s pi_iter:[99/100] update:[0.7]s kl:[0.0089] target_kl:[0.0100].\n",
      "   pi_loss:[-0.0162], entropy:[6.5556]\n",
      "[40/1000] rollout:[1.0]s pi_iter:[99/100] update:[0.7]s kl:[0.0077] target_kl:[0.0100].\n",
      "   pi_loss:[-0.0142], entropy:[6.1874]\n",
      "[50/1000] rollout:[1.0]s pi_iter:[10/100] update:[0.3]s kl:[0.0156] target_kl:[0.0100].\n",
      "   pi_loss:[-0.0151], entropy:[5.7660]\n",
      "[Eval. start] step:[50/1000][4.9%] #step:[0.0e+00] time:[00:01:26] ram:[72.4%].\n",
      "[Evaluate] ep_ret:[799.0602] ep_len:[1000]\n",
      "[../data/net/ppo_ant/model.npz] saved.\n",
      "[60/1000] rollout:[1.0]s pi_iter:[99/100] update:[0.7]s kl:[0.0085] target_kl:[0.0100].\n",
      "   pi_loss:[-0.0219], entropy:[5.4388]\n",
      "[70/1000] rollout:[1.0]s pi_iter:[99/100] update:[0.7]s kl:[0.0079] target_kl:[0.0100].\n",
      "   pi_loss:[-0.0202], entropy:[5.0390]\n",
      "[80/1000] rollout:[1.0]s pi_iter:[99/100] update:[0.7]s kl:[0.0096] target_kl:[0.0100].\n",
      "   pi_loss:[-0.0238], entropy:[4.7445]\n",
      "[90/1000] rollout:[1.0]s pi_iter:[99/100] update:[0.7]s kl:[0.0091] target_kl:[0.0100].\n",
      "   pi_loss:[-0.0431], entropy:[4.6008]\n",
      "[100/1000] rollout:[1.0]s pi_iter:[99/100] update:[0.7]s kl:[0.0096] target_kl:[0.0100].\n",
      "   pi_loss:[-0.0314], entropy:[4.4612]\n",
      "[Eval. start] step:[100/1000][9.9%] #step:[0.0e+00] time:[00:02:50] ram:[72.4%].\n",
      "[Evaluate] ep_ret:[803.9329] ep_len:[1000]\n",
      "[../data/net/ppo_ant/model.npz] saved.\n",
      "[110/1000] rollout:[1.0]s pi_iter:[99/100] update:[0.7]s kl:[0.0097] target_kl:[0.0100].\n",
      "   pi_loss:[-0.0112], entropy:[4.3071]\n",
      "[120/1000] rollout:[1.0]s pi_iter:[99/100] update:[0.7]s kl:[0.0085] target_kl:[0.0100].\n",
      "   pi_loss:[-0.0218], entropy:[3.9427]\n",
      "[130/1000] rollout:[1.0]s pi_iter:[42/100] update:[0.4]s kl:[0.0160] target_kl:[0.0100].\n",
      "   pi_loss:[-0.0400], entropy:[3.8015]\n",
      "[140/1000] rollout:[1.0]s pi_iter:[68/100] update:[0.5]s kl:[0.0152] target_kl:[0.0100].\n",
      "   pi_loss:[-0.0307], entropy:[3.4978]\n",
      "[150/1000] rollout:[1.0]s pi_iter:[99/100] update:[0.7]s kl:[0.0082] target_kl:[0.0100].\n",
      "   pi_loss:[-0.0257], entropy:[3.3191]\n",
      "[Eval. start] step:[150/1000][14.9%] #step:[0.0e+00] time:[00:04:12] ram:[72.5%].\n",
      "[Evaluate] ep_ret:[888.6821] ep_len:[1000]\n",
      "[../data/net/ppo_ant/model.npz] saved.\n",
      "[160/1000] rollout:[0.9]s pi_iter:[80/100] update:[0.6]s kl:[0.0153] target_kl:[0.0100].\n",
      "   pi_loss:[-0.0313], entropy:[3.1101]\n",
      "[170/1000] rollout:[1.0]s pi_iter:[61/100] update:[0.5]s kl:[0.0167] target_kl:[0.0100].\n",
      "   pi_loss:[-0.0253], entropy:[2.9840]\n",
      "[180/1000] rollout:[0.9]s pi_iter:[99/100] update:[0.7]s kl:[0.0098] target_kl:[0.0100].\n",
      "   pi_loss:[-0.0306], entropy:[2.8102]\n",
      "[190/1000] rollout:[0.9]s pi_iter:[92/100] update:[0.7]s kl:[0.0152] target_kl:[0.0100].\n",
      "   pi_loss:[-0.0327], entropy:[2.5038]\n",
      "[200/1000] rollout:[1.0]s pi_iter:[99/100] update:[0.7]s kl:[0.0099] target_kl:[0.0100].\n",
      "   pi_loss:[-0.0302], entropy:[2.3928]\n",
      "[Eval. start] step:[200/1000][19.9%] #step:[0.0e+00] time:[00:05:31] ram:[72.5%].\n",
      "[Evaluate] ep_ret:[1108.1032] ep_len:[1000]\n",
      "[../data/net/ppo_ant/model.npz] saved.\n",
      "[210/1000] rollout:[0.9]s pi_iter:[42/100] update:[0.4]s kl:[0.0153] target_kl:[0.0100].\n",
      "   pi_loss:[-0.0245], entropy:[2.3553]\n",
      "[220/1000] rollout:[0.9]s pi_iter:[61/100] update:[0.5]s kl:[0.0157] target_kl:[0.0100].\n",
      "   pi_loss:[-0.0169], entropy:[2.2151]\n",
      "[230/1000] rollout:[0.9]s pi_iter:[48/100] update:[0.5]s kl:[0.0155] target_kl:[0.0100].\n",
      "   pi_loss:[-0.0309], entropy:[1.9824]\n",
      "[240/1000] rollout:[0.9]s pi_iter:[20/100] update:[0.3]s kl:[0.0151] target_kl:[0.0100].\n",
      "   pi_loss:[-0.0121], entropy:[1.8396]\n",
      "[250/1000] rollout:[0.9]s pi_iter:[49/100] update:[0.5]s kl:[0.0155] target_kl:[0.0100].\n",
      "   pi_loss:[-0.0280], entropy:[1.8958]\n",
      "[Eval. start] step:[250/1000][24.9%] #step:[0.0e+00] time:[00:06:47] ram:[72.5%].\n",
      "[Evaluate] ep_ret:[1736.6795] ep_len:[1000]\n",
      "[../data/net/ppo_ant/model.npz] saved.\n",
      "[260/1000] rollout:[0.9]s pi_iter:[29/100] update:[0.4]s kl:[0.0154] target_kl:[0.0100].\n",
      "   pi_loss:[-0.0236], entropy:[1.7926]\n",
      "[270/1000] rollout:[0.9]s pi_iter:[17/100] update:[0.3]s kl:[0.0158] target_kl:[0.0100].\n",
      "   pi_loss:[-0.0018], entropy:[1.5619]\n",
      "[280/1000] rollout:[0.9]s pi_iter:[33/100] update:[0.4]s kl:[0.0151] target_kl:[0.0100].\n",
      "   pi_loss:[-0.0043], entropy:[1.3849]\n",
      "[290/1000] rollout:[0.9]s pi_iter:[35/100] update:[0.4]s kl:[0.0155] target_kl:[0.0100].\n",
      "   pi_loss:[-0.0226], entropy:[1.2318]\n",
      "[300/1000] rollout:[0.9]s pi_iter:[89/100] update:[0.6]s kl:[0.0157] target_kl:[0.0100].\n",
      "   pi_loss:[-0.0262], entropy:[1.0938]\n",
      "[Eval. start] step:[300/1000][29.9%] #step:[0.0e+00] time:[00:08:03] ram:[72.5%].\n",
      "[Evaluate] ep_ret:[1762.4139] ep_len:[1000]\n",
      "[../data/net/ppo_ant/model.npz] saved.\n",
      "[310/1000] rollout:[0.9]s pi_iter:[77/100] update:[0.6]s kl:[0.0160] target_kl:[0.0100].\n",
      "   pi_loss:[-0.0271], entropy:[1.0539]\n",
      "[320/1000] rollout:[0.9]s pi_iter:[43/100] update:[0.5]s kl:[0.0152] target_kl:[0.0100].\n",
      "   pi_loss:[-0.0199], entropy:[0.7818]\n",
      "[330/1000] rollout:[0.9]s pi_iter:[6/100] update:[0.3]s kl:[0.0168] target_kl:[0.0100].\n",
      "   pi_loss:[0.0080], entropy:[0.8421]\n",
      "[340/1000] rollout:[0.9]s pi_iter:[5/100] update:[0.3]s kl:[0.0153] target_kl:[0.0100].\n",
      "   pi_loss:[-0.0176], entropy:[0.7619]\n",
      "[350/1000] rollout:[0.9]s pi_iter:[5/100] update:[0.3]s kl:[0.0158] target_kl:[0.0100].\n",
      "   pi_loss:[-0.0047], entropy:[0.6969]\n",
      "[Eval. start] step:[350/1000][34.9%] #step:[0.0e+00] time:[00:09:15] ram:[72.5%].\n",
      "[Evaluate] ep_ret:[2228.7627] ep_len:[1000]\n",
      "[../data/net/ppo_ant/model.npz] saved.\n",
      "[360/1000] rollout:[0.9]s pi_iter:[47/100] update:[0.5]s kl:[0.0165] target_kl:[0.0100].\n",
      "   pi_loss:[-0.0274], entropy:[0.6699]\n",
      "[370/1000] rollout:[0.9]s pi_iter:[23/100] update:[0.4]s kl:[0.0181] target_kl:[0.0100].\n",
      "   pi_loss:[-0.0240], entropy:[0.4761]\n",
      "[380/1000] rollout:[0.9]s pi_iter:[12/100] update:[0.3]s kl:[0.0163] target_kl:[0.0100].\n",
      "   pi_loss:[-0.0053], entropy:[0.3971]\n",
      "[390/1000] rollout:[0.9]s pi_iter:[39/100] update:[0.4]s kl:[0.0151] target_kl:[0.0100].\n",
      "   pi_loss:[-0.0192], entropy:[0.3055]\n",
      "[400/1000] rollout:[0.9]s pi_iter:[15/100] update:[0.4]s kl:[0.0152] target_kl:[0.0100].\n",
      "   pi_loss:[-0.0013], entropy:[0.2296]\n",
      "[Eval. start] step:[400/1000][39.9%] #step:[0.0e+00] time:[00:10:26] ram:[72.5%].\n",
      "[Evaluate] ep_ret:[2126.1937] ep_len:[1000]\n",
      "[../data/net/ppo_ant/model.npz] saved.\n",
      "[410/1000] rollout:[1.0]s pi_iter:[73/100] update:[0.6]s kl:[0.0154] target_kl:[0.0100].\n",
      "   pi_loss:[-0.0166], entropy:[0.1267]\n",
      "[420/1000] rollout:[0.9]s pi_iter:[7/100] update:[0.3]s kl:[0.0152] target_kl:[0.0100].\n",
      "   pi_loss:[0.0013], entropy:[-0.0693]\n",
      "[430/1000] rollout:[0.9]s pi_iter:[22/100] update:[0.3]s kl:[0.0151] target_kl:[0.0100].\n",
      "   pi_loss:[-0.0331], entropy:[-0.0822]\n",
      "[440/1000] rollout:[0.9]s pi_iter:[28/100] update:[0.4]s kl:[0.0152] target_kl:[0.0100].\n",
      "   pi_loss:[-0.0119], entropy:[-0.1218]\n",
      "[450/1000] rollout:[0.9]s pi_iter:[99/100] update:[0.7]s kl:[0.0096] target_kl:[0.0100].\n",
      "   pi_loss:[-0.0371], entropy:[-0.2702]\n",
      "[Eval. start] step:[450/1000][44.9%] #step:[0.0e+00] time:[00:11:37] ram:[73.0%].\n",
      "[Evaluate] ep_ret:[2303.6478] ep_len:[1000]\n",
      "[../data/net/ppo_ant/model.npz] saved.\n",
      "[460/1000] rollout:[0.9]s pi_iter:[9/100] update:[0.3]s kl:[0.0162] target_kl:[0.0100].\n",
      "   pi_loss:[0.0147], entropy:[-0.2967]\n",
      "[470/1000] rollout:[0.9]s pi_iter:[99/100] update:[0.7]s kl:[0.0091] target_kl:[0.0100].\n",
      "   pi_loss:[-0.0324], entropy:[-0.3619]\n",
      "[480/1000] rollout:[0.9]s pi_iter:[24/100] update:[0.4]s kl:[0.0166] target_kl:[0.0100].\n",
      "   pi_loss:[-0.0238], entropy:[-0.5231]\n",
      "[490/1000] rollout:[0.9]s pi_iter:[94/100] update:[0.7]s kl:[0.0156] target_kl:[0.0100].\n",
      "   pi_loss:[-0.0173], entropy:[-0.5535]\n",
      "[500/1000] rollout:[0.9]s pi_iter:[99/100] update:[0.7]s kl:[0.0099] target_kl:[0.0100].\n",
      "   pi_loss:[-0.0116], entropy:[-0.6100]\n",
      "[Eval. start] step:[500/1000][49.9%] #step:[0.0e+00] time:[00:12:48] ram:[73.0%].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Evaluate] ep_ret:[2298.9375] ep_len:[1000]\n",
      "[../data/net/ppo_ant/model.npz] saved.\n",
      "[510/1000] rollout:[0.9]s pi_iter:[35/100] update:[0.4]s kl:[0.0151] target_kl:[0.0100].\n",
      "   pi_loss:[-0.0212], entropy:[-0.6092]\n",
      "[520/1000] rollout:[0.9]s pi_iter:[10/100] update:[0.3]s kl:[0.0162] target_kl:[0.0100].\n",
      "   pi_loss:[-0.0141], entropy:[-0.8745]\n",
      "[530/1000] rollout:[1.0]s pi_iter:[12/100] update:[0.3]s kl:[0.0158] target_kl:[0.0100].\n",
      "   pi_loss:[-0.0075], entropy:[-0.8806]\n",
      "[540/1000] rollout:[0.9]s pi_iter:[3/100] update:[0.3]s kl:[0.0165] target_kl:[0.0100].\n",
      "   pi_loss:[-0.0055], entropy:[-0.8774]\n",
      "[550/1000] rollout:[0.9]s pi_iter:[58/100] update:[0.5]s kl:[0.0159] target_kl:[0.0100].\n",
      "   pi_loss:[-0.0287], entropy:[-1.0688]\n",
      "[Eval. start] step:[550/1000][54.9%] #step:[0.0e+00] time:[00:13:57] ram:[73.3%].\n",
      "[Evaluate] ep_ret:[2400.0897] ep_len:[1000]\n",
      "[../data/net/ppo_ant/model.npz] saved.\n",
      "[560/1000] rollout:[0.9]s pi_iter:[26/100] update:[0.4]s kl:[0.0162] target_kl:[0.0100].\n",
      "   pi_loss:[-0.0040], entropy:[-1.0031]\n",
      "[570/1000] rollout:[0.9]s pi_iter:[47/100] update:[0.5]s kl:[0.0173] target_kl:[0.0100].\n",
      "   pi_loss:[-0.0243], entropy:[-1.0840]\n",
      "[580/1000] rollout:[1.0]s pi_iter:[5/100] update:[0.3]s kl:[0.0153] target_kl:[0.0100].\n",
      "   pi_loss:[0.0038], entropy:[-1.1512]\n",
      "[590/1000] rollout:[0.9]s pi_iter:[6/100] update:[0.3]s kl:[0.0159] target_kl:[0.0100].\n",
      "   pi_loss:[-0.0073], entropy:[-1.1912]\n",
      "[600/1000] rollout:[0.9]s pi_iter:[39/100] update:[0.4]s kl:[0.0153] target_kl:[0.0100].\n",
      "   pi_loss:[-0.0286], entropy:[-1.2253]\n",
      "[Eval. start] step:[600/1000][59.9%] #step:[0.0e+00] time:[00:15:05] ram:[73.0%].\n",
      "[Evaluate] ep_ret:[2308.1992] ep_len:[1000]\n",
      "[../data/net/ppo_ant/model.npz] saved.\n",
      "[610/1000] rollout:[0.9]s pi_iter:[29/100] update:[0.4]s kl:[0.0161] target_kl:[0.0100].\n",
      "   pi_loss:[-0.0069], entropy:[-1.2359]\n",
      "[620/1000] rollout:[0.9]s pi_iter:[41/100] update:[0.5]s kl:[0.0153] target_kl:[0.0100].\n",
      "   pi_loss:[0.0031], entropy:[-1.3688]\n",
      "[630/1000] rollout:[0.9]s pi_iter:[20/100] update:[0.3]s kl:[0.0150] target_kl:[0.0100].\n",
      "   pi_loss:[-0.0130], entropy:[-1.3623]\n",
      "[640/1000] rollout:[0.9]s pi_iter:[10/100] update:[0.3]s kl:[0.0153] target_kl:[0.0100].\n",
      "   pi_loss:[-0.0095], entropy:[-1.3964]\n",
      "[650/1000] rollout:[0.9]s pi_iter:[5/100] update:[0.3]s kl:[0.0167] target_kl:[0.0100].\n",
      "   pi_loss:[-0.0116], entropy:[-1.4697]\n",
      "[Eval. start] step:[650/1000][64.9%] #step:[0.0e+00] time:[00:16:13] ram:[73.0%].\n",
      "[Evaluate] ep_ret:[2449.3794] ep_len:[1000]\n",
      "[../data/net/ppo_ant/model.npz] saved.\n",
      "[660/1000] rollout:[0.9]s pi_iter:[4/100] update:[0.3]s kl:[0.0189] target_kl:[0.0100].\n",
      "   pi_loss:[0.0012], entropy:[-1.4597]\n",
      "[670/1000] rollout:[0.9]s pi_iter:[12/100] update:[0.3]s kl:[0.0152] target_kl:[0.0100].\n",
      "   pi_loss:[-0.0074], entropy:[-1.5266]\n",
      "[680/1000] rollout:[0.9]s pi_iter:[99/100] update:[0.7]s kl:[0.0109] target_kl:[0.0100].\n",
      "   pi_loss:[-0.0478], entropy:[-1.4975]\n",
      "[690/1000] rollout:[0.9]s pi_iter:[3/100] update:[0.3]s kl:[0.0170] target_kl:[0.0100].\n",
      "   pi_loss:[0.0127], entropy:[-1.5947]\n",
      "[700/1000] rollout:[0.9]s pi_iter:[27/100] update:[0.4]s kl:[0.0159] target_kl:[0.0100].\n",
      "   pi_loss:[-0.0279], entropy:[-1.7053]\n",
      "[Eval. start] step:[700/1000][69.9%] #step:[0.0e+00] time:[00:17:19] ram:[73.0%].\n",
      "[Evaluate] ep_ret:[2365.3293] ep_len:[1000]\n",
      "[../data/net/ppo_ant/model.npz] saved.\n",
      "[710/1000] rollout:[0.9]s pi_iter:[39/100] update:[0.4]s kl:[0.0176] target_kl:[0.0100].\n",
      "   pi_loss:[-0.0114], entropy:[-1.7060]\n",
      "[720/1000] rollout:[0.9]s pi_iter:[4/100] update:[0.3]s kl:[0.0180] target_kl:[0.0100].\n",
      "   pi_loss:[0.0045], entropy:[-1.7610]\n",
      "[730/1000] rollout:[0.9]s pi_iter:[3/100] update:[0.3]s kl:[0.0164] target_kl:[0.0100].\n",
      "   pi_loss:[-0.0167], entropy:[-1.8812]\n",
      "[740/1000] rollout:[0.9]s pi_iter:[4/100] update:[0.3]s kl:[0.0159] target_kl:[0.0100].\n",
      "   pi_loss:[0.0022], entropy:[-1.9033]\n",
      "[750/1000] rollout:[0.9]s pi_iter:[83/100] update:[0.6]s kl:[0.0155] target_kl:[0.0100].\n",
      "   pi_loss:[-0.0418], entropy:[-1.9123]\n",
      "[Eval. start] step:[750/1000][74.9%] #step:[0.0e+00] time:[00:18:26] ram:[73.0%].\n",
      "[Evaluate] ep_ret:[2467.1414] ep_len:[1000]\n",
      "[../data/net/ppo_ant/model.npz] saved.\n",
      "[760/1000] rollout:[0.9]s pi_iter:[5/100] update:[0.3]s kl:[0.0157] target_kl:[0.0100].\n",
      "   pi_loss:[-0.0019], entropy:[-1.8892]\n",
      "[770/1000] rollout:[0.9]s pi_iter:[12/100] update:[0.3]s kl:[0.0170] target_kl:[0.0100].\n",
      "   pi_loss:[-0.0021], entropy:[-1.9633]\n",
      "[780/1000] rollout:[0.9]s pi_iter:[3/100] update:[0.3]s kl:[0.0171] target_kl:[0.0100].\n",
      "   pi_loss:[-0.0204], entropy:[-1.9369]\n",
      "[790/1000] rollout:[0.9]s pi_iter:[55/100] update:[0.5]s kl:[0.0150] target_kl:[0.0100].\n",
      "   pi_loss:[-0.0248], entropy:[-2.0088]\n",
      "[800/1000] rollout:[0.9]s pi_iter:[64/100] update:[0.6]s kl:[0.0160] target_kl:[0.0100].\n",
      "   pi_loss:[-0.0001], entropy:[-2.0401]\n",
      "[Eval. start] step:[800/1000][79.9%] #step:[0.0e+00] time:[00:19:33] ram:[73.0%].\n",
      "[Evaluate] ep_ret:[2402.2737] ep_len:[1000]\n",
      "[../data/net/ppo_ant/model.npz] saved.\n",
      "[810/1000] rollout:[0.9]s pi_iter:[16/100] update:[0.3]s kl:[0.0172] target_kl:[0.0100].\n",
      "   pi_loss:[-0.0232], entropy:[-2.0338]\n",
      "[820/1000] rollout:[0.9]s pi_iter:[3/100] update:[0.3]s kl:[0.0171] target_kl:[0.0100].\n",
      "   pi_loss:[0.0239], entropy:[-2.1803]\n",
      "[830/1000] rollout:[0.9]s pi_iter:[4/100] update:[0.3]s kl:[0.0160] target_kl:[0.0100].\n",
      "   pi_loss:[-0.0162], entropy:[-2.2262]\n",
      "[840/1000] rollout:[0.9]s pi_iter:[22/100] update:[0.4]s kl:[0.0155] target_kl:[0.0100].\n",
      "   pi_loss:[-0.0191], entropy:[-2.2553]\n",
      "[850/1000] rollout:[0.9]s pi_iter:[12/100] update:[0.3]s kl:[0.0153] target_kl:[0.0100].\n",
      "   pi_loss:[-0.0065], entropy:[-2.2289]\n",
      "[Eval. start] step:[850/1000][84.9%] #step:[0.0e+00] time:[00:20:39] ram:[73.1%].\n",
      "[Evaluate] ep_ret:[2415.3483] ep_len:[1000]\n",
      "[../data/net/ppo_ant/model.npz] saved.\n",
      "[860/1000] rollout:[0.9]s pi_iter:[56/100] update:[0.5]s kl:[0.0153] target_kl:[0.0100].\n",
      "   pi_loss:[-0.0333], entropy:[-2.2569]\n",
      "[870/1000] rollout:[0.9]s pi_iter:[17/100] update:[0.3]s kl:[0.0163] target_kl:[0.0100].\n",
      "   pi_loss:[-0.0210], entropy:[-2.2733]\n",
      "[880/1000] rollout:[0.9]s pi_iter:[4/100] update:[0.3]s kl:[0.0177] target_kl:[0.0100].\n",
      "   pi_loss:[0.0148], entropy:[-2.2079]\n",
      "[890/1000] rollout:[0.9]s pi_iter:[7/100] update:[0.3]s kl:[0.0170] target_kl:[0.0100].\n",
      "   pi_loss:[-0.0148], entropy:[-2.2391]\n",
      "[900/1000] rollout:[0.9]s pi_iter:[4/100] update:[0.3]s kl:[0.0159] target_kl:[0.0100].\n",
      "   pi_loss:[0.0215], entropy:[-2.2857]\n",
      "[Eval. start] step:[900/1000][89.9%] #step:[0.0e+00] time:[00:21:45] ram:[73.0%].\n",
      "[Evaluate] ep_ret:[2496.5071] ep_len:[1000]\n",
      "[../data/net/ppo_ant/model.npz] saved.\n",
      "[910/1000] rollout:[0.9]s pi_iter:[15/100] update:[0.3]s kl:[0.0151] target_kl:[0.0100].\n",
      "   pi_loss:[-0.0058], entropy:[-2.2887]\n",
      "[920/1000] rollout:[0.9]s pi_iter:[24/100] update:[0.4]s kl:[0.0152] target_kl:[0.0100].\n",
      "   pi_loss:[-0.0357], entropy:[-2.4157]\n",
      "[930/1000] rollout:[0.9]s pi_iter:[17/100] update:[0.3]s kl:[0.0165] target_kl:[0.0100].\n",
      "   pi_loss:[-0.0048], entropy:[-2.3762]\n",
      "[940/1000] rollout:[0.9]s pi_iter:[7/100] update:[0.3]s kl:[0.0188] target_kl:[0.0100].\n",
      "   pi_loss:[-0.0245], entropy:[-2.3978]\n",
      "[950/1000] rollout:[0.9]s pi_iter:[26/100] update:[0.4]s kl:[0.0167] target_kl:[0.0100].\n",
      "   pi_loss:[-0.0085], entropy:[-2.4631]\n",
      "[Eval. start] step:[950/1000][94.9%] #step:[0.0e+00] time:[00:22:51] ram:[73.1%].\n",
      "[Evaluate] ep_ret:[2498.8336] ep_len:[1000]\n",
      "[../data/net/ppo_ant/model.npz] saved.\n",
      "[960/1000] rollout:[0.9]s pi_iter:[3/100] update:[0.3]s kl:[0.0240] target_kl:[0.0100].\n",
      "   pi_loss:[-0.0144], entropy:[-2.4802]\n",
      "[970/1000] rollout:[0.9]s pi_iter:[16/100] update:[0.3]s kl:[0.0155] target_kl:[0.0100].\n",
      "   pi_loss:[0.0026], entropy:[-2.4970]\n",
      "[980/1000] rollout:[0.9]s pi_iter:[18/100] update:[0.3]s kl:[0.0168] target_kl:[0.0100].\n",
      "   pi_loss:[-0.0266], entropy:[-2.4805]\n",
      "[990/1000] rollout:[0.9]s pi_iter:[5/100] update:[0.3]s kl:[0.0176] target_kl:[0.0100].\n",
      "   pi_loss:[-0.0122], entropy:[-2.5437]\n",
      "[1000/1000] rollout:[0.9]s pi_iter:[4/100] update:[0.3]s kl:[0.0183] target_kl:[0.0100].\n",
      "   pi_loss:[-0.0164], entropy:[-2.5906]\n",
      "[Eval. start] step:[1000/1000][99.9%] #step:[0.0e+00] time:[00:23:56] ram:[73.1%].\n",
      "[Evaluate] ep_ret:[2520.5118] ep_len:[1000]\n",
      "[../data/net/ppo_ant/model.npz] saved.\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "n_env_step = 0 # number of environment steps\n",
    "for t in range(int(total_steps)):\n",
    "    esec = time.time()-start_time\n",
    "    \n",
    "    # 1. Synchronize worker weights\n",
    "    weights = R.get_weights()\n",
    "    set_weights_list = [worker.set_weights.remote(weights) for worker in workers] \n",
    "    \n",
    "    # 2. Make rollout and accumulate to Buffers\n",
    "    t_start = time.time()\n",
    "    ops = [worker.rollout.remote() for worker in workers]\n",
    "    rollout_vals = ray.get(ops)\n",
    "    sec_rollout = time.time() - t_start\n",
    "    \n",
    "    # 3. Update\n",
    "    t_start = time.time() # tic\n",
    "    \"\"\" \n",
    "    # Old update routine with batch learning \n",
    "    # Get stats before update\n",
    "    feeds_list = []\n",
    "    for rollout_val in rollout_vals:\n",
    "        feeds = {k:v for k,v in zip(R.model['all_phs'],rollout_val)}\n",
    "        feeds_list.append(feeds)\n",
    "        pi_l_old, v_l_old, ent = R.sess.run(\n",
    "            [R.graph['pi_loss'],R.graph['v_loss'],R.graph['approx_ent']],feed_dict=feeds)\n",
    "    # Update the central agent \n",
    "    for _ in range(train_pi_iters):\n",
    "        for r_idx,rollout_val in enumerate(rollout_vals):\n",
    "            feeds = feeds_list[r_idx]\n",
    "            _, kl = R.sess.run([R.graph['train_pi'],R.graph['approx_kl']],feed_dict=feeds)\n",
    "            if kl > 1.5 * target_kl:\n",
    "                print (\"kl(%.3f) is higher than 1.5x(%.3f)\"%(kl,target_kl))\n",
    "                break\n",
    "    for _ in range(train_v_iters):\n",
    "        for r_idx,rollout_val in enumerate(rollout_vals):\n",
    "            feeds = feeds_list[r_idx]\n",
    "            R.sess.run(R.graph['train_v'],feed_dict=feeds)\n",
    "    # Get stats after update\n",
    "    for r_idx,rollout_val in enumerate(rollout_vals):\n",
    "        feeds = feeds_list[r_idx]\n",
    "        pi_l_new,v_l_new,kl,cf = R.sess.run(\n",
    "            [R.graph['pi_loss'],R.graph['v_loss'],R.graph['approx_kl'],R.graph['clipfrac']],\n",
    "            feed_dict=feeds)\n",
    "    \"\"\" \n",
    "    # Mini-batch type of update\n",
    "    for r_idx,rval in enumerate(rollout_vals):\n",
    "        obs_buf,act_buf,adv_buf,ret_buf,logp_buf = \\\n",
    "            rval[0],rval[1],rval[2],rval[3],rval[4]\n",
    "        if r_idx == 0:\n",
    "            obs_bufs,act_bufs,adv_bufs,ret_bufs,logp_bufs = \\\n",
    "                obs_buf,act_buf,adv_buf,ret_buf,logp_buf\n",
    "        else:\n",
    "            obs_bufs = np.concatenate((obs_bufs,obs_buf),axis=0)\n",
    "            act_bufs = np.concatenate((act_bufs,act_buf),axis=0)\n",
    "            adv_bufs = np.concatenate((adv_bufs,adv_buf),axis=0)\n",
    "            ret_bufs = np.concatenate((ret_bufs,ret_buf),axis=0)\n",
    "            logp_bufs = np.concatenate((logp_bufs,logp_buf),axis=0)\n",
    "    n_val_total = obs_bufs.shape[0]\n",
    "    for pi_iter in range(train_pi_iters):\n",
    "        rand_idx = np.random.permutation(n_val_total)[:batch_size]\n",
    "        buf_batches = [obs_bufs[rand_idx],act_bufs[rand_idx],adv_bufs[rand_idx],\n",
    "                       ret_bufs[rand_idx],logp_bufs[rand_idx]]\n",
    "        feeds = {k:v for k,v in zip(R.model['all_phs'],buf_batches)}\n",
    "        _,kl,pi_loss,ent = R.sess.run([R.graph['train_pi'],R.graph['approx_kl'],\n",
    "                               R.graph['pi_loss'],R.graph['approx_ent']],\n",
    "                           feed_dict=feeds)        \n",
    "        if kl > 1.5 * target_kl:\n",
    "            # print (\"  pi_iter:[%d] kl(%.3f) is higher than 1.5x(%.3f)\"%(pi_iter,kl,target_kl))\n",
    "            break\n",
    "    for _ in range(train_v_iters):\n",
    "        rand_idx = np.random.permutation(n_val_total)[:batch_size]\n",
    "        buf_batches = [obs_bufs[rand_idx],act_bufs[rand_idx],adv_bufs[rand_idx],\n",
    "                       ret_bufs[rand_idx],logp_bufs[rand_idx]]\n",
    "        feeds = {k:v for k,v in zip(R.model['all_phs'],buf_batches)}\n",
    "        R.sess.run(R.graph['train_v'],feed_dict=feeds)\n",
    "    sec_update = time.time() - t_start # toc\n",
    "    \n",
    "    # Print\n",
    "    if (t == 0) or (((t+1)%print_every) == 0): \n",
    "        print (\"[%d/%d] rollout:[%.1f]s pi_iter:[%d/%d] update:[%.1f]s kl:[%.4f] target_kl:[%.4f].\"%\n",
    "               (t+1,total_steps,sec_rollout,pi_iter,train_pi_iters,sec_update,kl,target_kl))\n",
    "        print (\"   pi_loss:[%.4f], entropy:[%.4f]\"%\n",
    "               (pi_loss,ent))\n",
    "        \n",
    "    # Evaluate\n",
    "    if (t==0) or (((t+1)%evaluate_every) == 0):\n",
    "        ram_percent = psutil.virtual_memory().percent # memory usage\n",
    "        print (\"[Eval. start] step:[%d/%d][%.1f%%] #step:[%.1e] time:[%s] ram:[%.1f%%].\"%\n",
    "               (t+1,total_steps,t/total_steps*100,\n",
    "                n_env_step,\n",
    "                time.strftime(\"%H:%M:%S\", time.gmtime(time.time()-start_time)),\n",
    "                ram_percent)\n",
    "              )\n",
    "        o,d,ep_ret,ep_len = eval_env.reset(),False,0,0\n",
    "        _ = eval_env.render(mode='human') \n",
    "        while not(d or (ep_len == max_ep_len)):\n",
    "            a = R.sess.run(R.model['mu'],feed_dict={R.model['o_ph']:o.reshape(1,-1)})\n",
    "            o,r,d,_ = eval_env.step(a[0])\n",
    "            _ = eval_env.render(mode='human') \n",
    "            ep_ret += r # compute return \n",
    "            ep_len += 1\n",
    "        print (\"[Evaluate] ep_ret:[%.4f] ep_len:[%d]\"%(ep_ret,ep_len))\n",
    "        \n",
    "        # Save \n",
    "        npz_path = '../data/net/ppo_ant/model.npz'\n",
    "        save_ppo_model(npz_path,R,VERBOSE=False)\n",
    "\n",
    "    \n",
    "print (\"Done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Close"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "ray.shutdown()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Re-init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "R.sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Restore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[../data/net/ppo_ant/model.npz] loaded.\n"
     ]
    }
   ],
   "source": [
    "npz_path = '../data/net/ppo_ant/model.npz'\n",
    "restore_ppo_model(npz_path,R,VERBOSE=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Evaluate] ep_ret:[2472.4729] ep_len:[1000]\n"
     ]
    }
   ],
   "source": [
    "eval_env = get_eval_env()\n",
    "o,d,ep_ret,ep_len = eval_env.reset(),False,0,0\n",
    "_ = eval_env.render(mode='human') \n",
    "while not(d or (ep_len == max_ep_len)):\n",
    "    a = R.sess.run(R.model['mu'],feed_dict={R.model['o_ph']:o.reshape(1,-1)})\n",
    "    o,r,d,_ = eval_env.step(a[0])\n",
    "    _ = eval_env.render(mode='human') \n",
    "    ep_ret += r # compute return \n",
    "    ep_len += 1\n",
    "print (\"[Evaluate] ep_ret:[%.4f] ep_len:[%d]\"%(ep_ret,ep_len))\n",
    "eval_env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
