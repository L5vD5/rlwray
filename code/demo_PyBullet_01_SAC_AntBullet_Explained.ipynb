{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SAC on Ant Bullet <font color='grey'> (*Self-Contained*) </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Packaged loaded. TF version is [1.14.0].\n"
     ]
    }
   ],
   "source": [
    "import datetime,gym,os,pybullet_envs,time,os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "np.set_printoptions(precision=2)\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)\n",
    "print (\"Packaged loaded. TF version is [%s].\"%(tf.__version__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import deque"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Replay Buffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReplayBuffer:\n",
    "    \"\"\"\n",
    "    A simple FIFO experience replay buffer for SAC agents.\n",
    "    \"\"\"\n",
    "    def __init__(self, odim, adim, size):\n",
    "        self.obs1_buf = np.zeros([size, odim], dtype=np.float32)\n",
    "        self.obs2_buf = np.zeros([size, odim], dtype=np.float32)\n",
    "        self.acts_buf = np.zeros([size, adim], dtype=np.float32)\n",
    "        self.rews_buf = np.zeros(size, dtype=np.float32)\n",
    "        self.done_buf = np.zeros(size, dtype=np.float32)\n",
    "        self.ptr, self.size, self.max_size = 0, 0, size\n",
    "    def store(self, obs, act, rew, next_obs, done):\n",
    "        self.obs1_buf[self.ptr] = obs\n",
    "        self.obs2_buf[self.ptr] = next_obs\n",
    "        self.acts_buf[self.ptr] = act\n",
    "        self.rews_buf[self.ptr] = rew\n",
    "        self.done_buf[self.ptr] = done\n",
    "        self.ptr = (self.ptr+1) % self.max_size\n",
    "        self.size = min(self.size+1, self.max_size)\n",
    "    def sample_batch(self, batch_size=32):\n",
    "        idxs = np.random.randint(0, self.size, size=batch_size)\n",
    "        return dict(obs1=self.obs1_buf[idxs],\n",
    "                    obs2=self.obs2_buf[idxs],\n",
    "                    acts=self.acts_buf[idxs],\n",
    "                    rews=self.rews_buf[idxs],\n",
    "                    done=self.done_buf[idxs])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Soft Actor Critic Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAC model ready.\n"
     ]
    }
   ],
   "source": [
    "def create_sac_model(odim=10,adim=2,hdims=[256,256]):\n",
    "    \"\"\"\n",
    "    Soft Actor Critic Model (compatible with Ray)\n",
    "    \"\"\"\n",
    "    import tensorflow as tf # make it compatible with Ray actors\n",
    "    \n",
    "    def mlp(x,hdims=[256,256],actv=tf.nn.relu,out_actv=tf.nn.relu):\n",
    "        ki = tf.truncated_normal_initializer(stddev=0.1)\n",
    "        for hdim in hdims[:-1]:\n",
    "            x = tf.layers.dense(x,units=hdim,activation=actv,kernel_initializer=ki)\n",
    "        return tf.layers.dense(x,units=hdims[-1],activation=out_actv,kernel_initializer=ki)\n",
    "    def gaussian_loglik(x,mu,log_std):\n",
    "        EPS = 1e-8\n",
    "        pre_sum = -0.5*(\n",
    "            ( (x-mu)/(tf.exp(log_std)+EPS) )**2 +\n",
    "            2*log_std + np.log(2*np.pi)\n",
    "        )\n",
    "        return tf.reduce_sum(pre_sum, axis=1)\n",
    "    def mlp_gaussian_policy(o,adim=2,hdims=[256,256],actv=tf.nn.relu):\n",
    "        net = mlp(x=o,hdims=hdims,actv=actv,out_actv=actv) # feature \n",
    "        mu = tf.layers.dense(net,adim,activation=None) # mu\n",
    "        log_std = tf.layers.dense(net,adim,activation=None) # log_std\n",
    "        LOG_STD_MIN,LOG_STD_MAX = -10.0,+2.0\n",
    "        log_std = tf.clip_by_value(log_std, LOG_STD_MIN, LOG_STD_MAX) \n",
    "        std = tf.exp(log_std) # std \n",
    "        pi = mu + tf.random_normal(tf.shape(mu)) * std  # sampled\n",
    "        logp_pi = gaussian_loglik(x=pi,mu=mu,log_std=log_std) # log lik\n",
    "        return mu,pi,logp_pi\n",
    "    def squash_action(mu,pi,logp_pi):\n",
    "        # Squash those unbounded actions\n",
    "        logp_pi -= tf.reduce_sum(2*(np.log(2) - pi -\n",
    "                                    tf.nn.softplus(-2*pi)), axis=1)\n",
    "        mu,pi = tf.tanh(mu),tf.tanh(pi)\n",
    "        return mu, pi, logp_pi\n",
    "    def mlp_actor_critic(o,a,hdims=[256,256],actv=tf.nn.relu,out_actv=None,\n",
    "                         policy=mlp_gaussian_policy):\n",
    "        adim = a.shape.as_list()[-1]\n",
    "        with tf.variable_scope('pi'): # policy\n",
    "            mu,pi,logp_pi = policy(o=o,adim=adim,hdims=hdims,actv=actv)\n",
    "            mu,pi,logp_pi = squash_action(mu=mu,pi=pi,logp_pi=logp_pi)\n",
    "        def vf_mlp(x): return tf.squeeze(\n",
    "            mlp(x=x,hdims=hdims+[1],actv=actv,out_actv=None),axis=1)\n",
    "        with tf.variable_scope('q1'): q1 = vf_mlp( tf.concat([o,a],axis=-1))\n",
    "        with tf.variable_scope('q2'): q2 = vf_mlp( tf.concat([o,a],axis=-1))\n",
    "        return mu,pi,logp_pi,q1,q2\n",
    "    \n",
    "    def placeholder(dim=None):\n",
    "        return tf.placeholder(dtype=tf.float32,shape=(None,dim) if dim else (None,))\n",
    "    def placeholders(*args):\n",
    "        \"\"\"\n",
    "        Usage: a_ph,b_ph,c_ph = placeholders(adim,bdim,None)\n",
    "        \"\"\"\n",
    "        return [placeholder(dim) for dim in args]\n",
    "    def get_vars(scope):\n",
    "        return [x for x in tf.compat.v1.global_variables() if scope in x.name]\n",
    "    \n",
    "    # Have own session\n",
    "    config = tf.ConfigProto()\n",
    "    config.gpu_options.allow_growth = True\n",
    "    sess = tf.Session(config=config)\n",
    "    \n",
    "    # Placeholders\n",
    "    o_ph,a_ph,o2_ph,r_ph,d_ph = placeholders(odim,adim,odim,None,None)\n",
    "    # Actor critic \n",
    "    ac_kwargs = {'hdims':hdims,'actv':tf.nn.relu,'out_actv':None,'policy':mlp_gaussian_policy}\n",
    "    with tf.variable_scope('main'):\n",
    "        mu,pi,logp_pi,q1,q2 = mlp_actor_critic(o=o_ph,a=a_ph,**ac_kwargs)\n",
    "    with tf.variable_scope('main',reuse=True):\n",
    "        _,_,_,q1_pi,q2_pi = mlp_actor_critic(o=o_ph,a=pi,**ac_kwargs)\n",
    "        _,pi_next,logp_pi_next,_,_ = mlp_actor_critic(o=o2_ph,a=a_ph,**ac_kwargs)\n",
    "    # Target value\n",
    "    with tf.variable_scope('target'):\n",
    "        _,_,_,q1_targ,q2_targ = mlp_actor_critic(o=o2_ph,a=pi_next,**ac_kwargs)\n",
    "\n",
    "    # Get variables\n",
    "    main_vars,q_vars,pi_vars,target_vars = \\\n",
    "        get_vars('main'),get_vars('main/q'),get_vars('main/pi'),get_vars('target')\n",
    "    \n",
    "    model = {'o_ph':o_ph,'a_ph':a_ph,'o2_ph':o2_ph,'r_ph':r_ph,'d_ph':d_ph,\n",
    "             'mu':mu,'pi':pi,'logp_pi':logp_pi,'q1':q1,'q2':q2,\n",
    "             'q1_pi':q1_pi,'q2_pi':q2_pi,\n",
    "             'pi_next':pi_next,'logp_pi_next':logp_pi_next,\n",
    "             'q1_targ':q1_targ,'q2_targ':q2_targ,\n",
    "             'main_vars':main_vars,'q_vars':q_vars,'pi_vars':pi_vars,'target_vars':target_vars}\n",
    "        \n",
    "    return model,sess\n",
    "\n",
    "def create_sac_graph(model,lr=1e-3,gamma=0.98,alpha=0.1,polyak=0.995):\n",
    "    \"\"\"\n",
    "    SAC Computational Graph\n",
    "    \"\"\"\n",
    "    # Double Q-learning\n",
    "    min_q_pi = tf.minimum(model['q1_pi'],model['q2_pi'])\n",
    "    min_q_targ = tf.minimum(model['q1_targ'],model['q2_targ'])\n",
    "    \n",
    "    # Entropy-regularized Bellman backup\n",
    "    q_backup = tf.stop_gradient(\n",
    "        model['r_ph'] + \n",
    "        gamma*(1-model['d_ph'])*(min_q_targ - alpha*model['logp_pi_next'])\n",
    "    )\n",
    "    \n",
    "    # Soft actor-critic losses\n",
    "    pi_loss = tf.reduce_mean(alpha*model['logp_pi'] - min_q_pi)\n",
    "    q1_loss = 0.5 * tf.reduce_mean((q_backup - model['q1'])**2)\n",
    "    q2_loss = 0.5 * tf.reduce_mean((q_backup - model['q2'])**2)\n",
    "    value_loss = q1_loss + q2_loss\n",
    "    \n",
    "    # Policy train op\n",
    "    pi_optimizer = tf.train.AdamOptimizer(learning_rate=lr)\n",
    "    train_pi_op = pi_optimizer.minimize(pi_loss,var_list=model['pi_vars'])\n",
    "\n",
    "    # Value train op \n",
    "    value_optimizer = tf.train.AdamOptimizer(learning_rate=lr)\n",
    "    \n",
    "    with tf.control_dependencies([train_pi_op]):\n",
    "        train_value_op = value_optimizer.minimize(value_loss,var_list=model['q_vars'])\n",
    "        \n",
    "    # Polyak averaging for target variables\n",
    "    with tf.control_dependencies([train_value_op]):\n",
    "        target_update = tf.group([tf.assign(v_targ, polyak*v_targ + (1-polyak)*v_main)\n",
    "                                  for v_main, v_targ in \n",
    "                                      zip(model['main_vars'], model['target_vars'])]\n",
    "                                )\n",
    "    \n",
    "    # Tensorboard\n",
    "    pl, pi_loss_update_op = tf.metrics.mean(pi_loss)\n",
    "    vl, val_loss_update_op = tf.metrics.mean(value_loss)\n",
    "\n",
    "    summary = tf.summary.merge([tf.summary.scalar('policy_loss', pl), tf.summary.scalar('value_loss', vl)])\n",
    "\n",
    "    # All ops to call during one training step\n",
    "    step_ops = [pi_loss, q1_loss, q2_loss, model['q1'], model['q2'], model['logp_pi'], model['logp_pi_next'],model['q1_targ'],model['q2_targ'],model['q_vars'], model['pi_vars'],\n",
    "                train_pi_op, train_value_op, target_update]\n",
    "    \n",
    "    # Initializing targets to match main variables\n",
    "    target_init = tf.group([tf.assign(v_targ, v_main)\n",
    "                            for v_main, v_targ in \n",
    "                                zip(model['main_vars'], model['target_vars'])]\n",
    "                          )\n",
    "\n",
    "    return step_ops,target_init, pi_loss_update_op, val_loss_update_op, summary\n",
    "    \n",
    "def get_action(model,sess,o,deterministic=False):\n",
    "    act_op = model['mu'] if deterministic else model['pi']\n",
    "    return sess.run(act_op, feed_dict={model['o_ph']:o.reshape(1,-1)})[0]\n",
    "\n",
    "print (\"SAC model ready.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[AntBulletEnv-v0] ready.\n",
      "odim:[28] adim:[8].\n"
     ]
    }
   ],
   "source": [
    "gym.logger.set_level(40)\n",
    "env_name = 'AntBulletEnv-v0'\n",
    "env,test_env = gym.make(env_name),gym.make(env_name)\n",
    "_ = test_env.render(mode='human') # enable rendering on test_env\n",
    "_ = test_env.reset()\n",
    "for _ in range(3): # dummy run for proper rendering \n",
    "    a = test_env.action_space.sample()\n",
    "    o,r,d,_ = test_env.step(a)\n",
    "    time.sleep(0.01)\n",
    "print (\"[%s] ready.\"%(env_name))\n",
    "observation_space = env.observation_space\n",
    "action_space = env.action_space # -1.0 ~ +1.0\n",
    "odim,adim = observation_space.shape[0],action_space.shape[0]\n",
    "print (\"odim:[%d] adim:[%d].\"%(odim,adim))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize SAC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f9afb91bcc0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f9afb91bcc0>>: AttributeError: module 'gast' has no attribute 'Index'\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f9afb91ba58>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f9afb91ba58>>: AttributeError: module 'gast' has no attribute 'Index'\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f9af5178358>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f9af5178358>>: AttributeError: module 'gast' has no attribute 'Index'\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f9af5178358>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f9af5178358>>: AttributeError: module 'gast' has no attribute 'Index'\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f9ae2936a20>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f9ae2936a20>>: AttributeError: module 'gast' has no attribute 'Index'\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f9ae2936a20>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f9ae2936a20>>: AttributeError: module 'gast' has no attribute 'Index'\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f9afb91bb70>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f9afb91bb70>>: AttributeError: module 'gast' has no attribute 'Index'\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f9ae29360b8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f9ae29360b8>>: AttributeError: module 'gast' has no attribute 'Index'\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f9ae29360b8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f9ae29360b8>>: AttributeError: module 'gast' has no attribute 'Index'\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f9afb91bb38>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f9afb91bb38>>: AttributeError: module 'gast' has no attribute 'Index'\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f9ae297c278>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f9ae297c278>>: AttributeError: module 'gast' has no attribute 'Index'\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f9afb91bb38>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f9afb91bb38>>: AttributeError: module 'gast' has no attribute 'Index'\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f9afb91bac8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f9afb91bac8>>: AttributeError: module 'gast' has no attribute 'Index'\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f9afb91bac8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f9afb91bac8>>: AttributeError: module 'gast' has no attribute 'Index'\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f9ae2a71b00>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f9ae2a71b00>>: AttributeError: module 'gast' has no attribute 'Index'\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f9ae2a71b00>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f9ae2a71b00>>: AttributeError: module 'gast' has no attribute 'Index'\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f9ae29926d8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f9ae29926d8>>: AttributeError: module 'gast' has no attribute 'Index'\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f9ae2a71b00>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f9ae2a71b00>>: AttributeError: module 'gast' has no attribute 'Index'\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f9ae2a71b00>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f9ae2a71b00>>: AttributeError: module 'gast' has no attribute 'Index'\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f9ae29360b8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f9ae29360b8>>: AttributeError: module 'gast' has no attribute 'Index'\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f9ae2abd780>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f9ae2abd780>>: AttributeError: module 'gast' has no attribute 'Index'\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f9ae2992828>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f9ae2992828>>: AttributeError: module 'gast' has no attribute 'Index'\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f9ae2992a58>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f9ae2992a58>>: AttributeError: module 'gast' has no attribute 'Index'\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f9ae2992a58>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f9ae2992a58>>: AttributeError: module 'gast' has no attribute 'Index'\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f9ae2af9e10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f9ae2af9e10>>: AttributeError: module 'gast' has no attribute 'Index'\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f9ae2af9e10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f9ae2af9e10>>: AttributeError: module 'gast' has no attribute 'Index'\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f9ae2a48828>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f9ae2a48828>>: AttributeError: module 'gast' has no attribute 'Index'\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f9ae2669c18>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f9ae2669c18>>: AttributeError: module 'gast' has no attribute 'Index'\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f9ae2669c18>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f9ae2669c18>>: AttributeError: module 'gast' has no attribute 'Index'\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f9ae29a0dd8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f9ae29a0dd8>>: AttributeError: module 'gast' has no attribute 'Index'\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f9ae2c50da0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f9ae2c50da0>>: AttributeError: module 'gast' has no attribute 'Index'\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f9ae2936588>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f9ae2936588>>: AttributeError: module 'gast' has no attribute 'Index'\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f9ae29360b8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f9ae29360b8>>: AttributeError: module 'gast' has no attribute 'Index'\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f9ae29360b8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f9ae29360b8>>: AttributeError: module 'gast' has no attribute 'Index'\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f9ae2d3bc50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f9ae2d3bc50>>: AttributeError: module 'gast' has no attribute 'Index'\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f9ae2d3bc50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f9ae2d3bc50>>: AttributeError: module 'gast' has no attribute 'Index'\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f9ae29362e8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f9ae29362e8>>: AttributeError: module 'gast' has no attribute 'Index'\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f9ae2d6a710>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f9ae2d6a710>>: AttributeError: module 'gast' has no attribute 'Index'\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f9ae2d3bc50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f9ae2d3bc50>>: AttributeError: module 'gast' has no attribute 'Index'\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f9ae2cce6d8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f9ae2cce6d8>>: AttributeError: module 'gast' has no attribute 'Index'\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "model,sess = create_sac_model(odim=odim,adim=adim)\n",
    "step_ops,target_init,pi_loss_update_op,val_loss_update_op,summary = create_sac_graph(model,lr=1e-3,gamma=0.98,alpha=0.1,polyak=0.995)\n",
    "# Replay buffers\n",
    "replay_buffer = ReplayBuffer(odim=odim,adim=adim,size=int(1e6))\n",
    "replay_buffer_short = ReplayBuffer(odim=odim,adim=adim,size=int(1e5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training configuration \n",
    "total_steps,start_steps = 1e6,1e4\n",
    "update_every,update_count,batch_size,max_ep_len_train = 1,2,128,1e3\n",
    "evaluate_every,num_eval,max_ep_len_test = 1e4,3,1e3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix random seed and initialize the model\n",
    "seed = 0\n",
    "tf.set_random_seed(seed)\n",
    "np.random.seed(seed)    \n",
    "log_path = \"./log/\" + datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "summary_writer = tf.summary.FileWriter(log_path + \"/summary/\", graph=sess.graph)\n",
    "sess.run(tf.global_variables_initializer())\n",
    "sess.run(tf.local_variables_initializer())\n",
    "sess.run(target_init)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Evaluate] step:[10000/1000000][1.0%] time:00:00:09.\n",
      "[Evaluate] [0/3] ep_ret:[6.5715] ep_len:[20]\n",
      "[Evaluate] [1/3] ep_ret:[6.8594] ep_len:[20]\n",
      "[Evaluate] [2/3] ep_ret:[7.1275] ep_len:[20]\n",
      "[Evaluate] step:[20000/1000000][2.0%] time:00:02:20.\n",
      "[Evaluate] [0/3] ep_ret:[444.9378] ep_len:[1000]\n",
      "[Evaluate] [1/3] ep_ret:[265.0125] ep_len:[1000]\n",
      "[Evaluate] [2/3] ep_ret:[534.5338] ep_len:[1000]\n",
      "[Evaluate] step:[30000/1000000][3.0%] time:00:04:31.\n",
      "[Evaluate] [0/3] ep_ret:[400.4657] ep_len:[1000]\n",
      "[Evaluate] [1/3] ep_ret:[531.3713] ep_len:[1000]\n",
      "[Evaluate] [2/3] ep_ret:[445.9199] ep_len:[1000]\n",
      "[Evaluate] step:[40000/1000000][4.0%] time:00:06:34.\n",
      "[Evaluate] [0/3] ep_ret:[723.9842] ep_len:[1000]\n",
      "[Evaluate] [1/3] ep_ret:[863.3589] ep_len:[1000]\n",
      "[Evaluate] [2/3] ep_ret:[860.8565] ep_len:[1000]\n",
      "[Evaluate] step:[50000/1000000][5.0%] time:00:08:36.\n",
      "[Evaluate] [0/3] ep_ret:[904.5771] ep_len:[1000]\n",
      "[Evaluate] [1/3] ep_ret:[696.8711] ep_len:[1000]\n",
      "[Evaluate] [2/3] ep_ret:[811.9292] ep_len:[1000]\n",
      "[Evaluate] step:[60000/1000000][6.0%] time:00:10:38.\n",
      "[Evaluate] [0/3] ep_ret:[864.6208] ep_len:[1000]\n",
      "[Evaluate] [1/3] ep_ret:[839.2264] ep_len:[1000]\n",
      "[Evaluate] [2/3] ep_ret:[956.4330] ep_len:[1000]\n",
      "[Evaluate] step:[70000/1000000][7.0%] time:00:12:41.\n",
      "[Evaluate] [0/3] ep_ret:[1103.5938] ep_len:[1000]\n",
      "[Evaluate] [1/3] ep_ret:[1190.1849] ep_len:[1000]\n",
      "[Evaluate] [2/3] ep_ret:[1278.2791] ep_len:[1000]\n",
      "[Evaluate] step:[80000/1000000][8.0%] time:00:14:43.\n",
      "[Evaluate] [0/3] ep_ret:[972.2510] ep_len:[1000]\n",
      "[Evaluate] [1/3] ep_ret:[1074.2209] ep_len:[1000]\n",
      "[Evaluate] [2/3] ep_ret:[935.4258] ep_len:[1000]\n",
      "[Evaluate] step:[90000/1000000][9.0%] time:00:16:45.\n",
      "[Evaluate] [0/3] ep_ret:[1101.4126] ep_len:[1000]\n",
      "[Evaluate] [1/3] ep_ret:[831.5836] ep_len:[1000]\n",
      "[Evaluate] [2/3] ep_ret:[844.4534] ep_len:[1000]\n",
      "[Evaluate] step:[100000/1000000][10.0%] time:00:18:48.\n",
      "[Evaluate] [0/3] ep_ret:[1037.2719] ep_len:[1000]\n",
      "[Evaluate] [1/3] ep_ret:[991.8033] ep_len:[1000]\n",
      "[Evaluate] [2/3] ep_ret:[1019.6907] ep_len:[1000]\n",
      "[Evaluate] step:[110000/1000000][11.0%] time:00:20:50.\n",
      "[Evaluate] [0/3] ep_ret:[1100.8087] ep_len:[1000]\n",
      "[Evaluate] [1/3] ep_ret:[939.5227] ep_len:[1000]\n",
      "[Evaluate] [2/3] ep_ret:[885.1576] ep_len:[1000]\n",
      "[Evaluate] step:[120000/1000000][12.0%] time:00:22:53.\n",
      "[Evaluate] [0/3] ep_ret:[1150.5672] ep_len:[1000]\n",
      "[Evaluate] [1/3] ep_ret:[1313.7692] ep_len:[1000]\n",
      "[Evaluate] [2/3] ep_ret:[1312.4581] ep_len:[1000]\n",
      "[Evaluate] step:[130000/1000000][13.0%] time:00:25:00.\n",
      "[Evaluate] [0/3] ep_ret:[914.2480] ep_len:[1000]\n",
      "[Evaluate] [1/3] ep_ret:[1068.3457] ep_len:[1000]\n",
      "[Evaluate] [2/3] ep_ret:[1069.6826] ep_len:[1000]\n",
      "[Evaluate] step:[140000/1000000][14.0%] time:00:27:02.\n",
      "[Evaluate] [0/3] ep_ret:[1540.3020] ep_len:[1000]\n",
      "[Evaluate] [1/3] ep_ret:[1552.6893] ep_len:[1000]\n",
      "[Evaluate] [2/3] ep_ret:[1550.3812] ep_len:[1000]\n",
      "[Evaluate] step:[150000/1000000][15.0%] time:00:29:05.\n",
      "[Evaluate] [0/3] ep_ret:[1690.5836] ep_len:[1000]\n",
      "[Evaluate] [1/3] ep_ret:[1693.8628] ep_len:[1000]\n",
      "[Evaluate] [2/3] ep_ret:[1691.9133] ep_len:[1000]\n",
      "[Evaluate] step:[160000/1000000][16.0%] time:00:31:07.\n",
      "[Evaluate] [0/3] ep_ret:[1568.6065] ep_len:[1000]\n",
      "[Evaluate] [1/3] ep_ret:[1570.0862] ep_len:[1000]\n",
      "[Evaluate] [2/3] ep_ret:[1554.3953] ep_len:[1000]\n",
      "[Evaluate] step:[170000/1000000][17.0%] time:00:33:09.\n",
      "[Evaluate] [0/3] ep_ret:[1739.9162] ep_len:[1000]\n",
      "[Evaluate] [1/3] ep_ret:[1714.2322] ep_len:[1000]\n",
      "[Evaluate] [2/3] ep_ret:[1722.6000] ep_len:[1000]\n",
      "[Evaluate] step:[180000/1000000][18.0%] time:00:35:13.\n",
      "[Evaluate] [0/3] ep_ret:[1773.0695] ep_len:[1000]\n",
      "[Evaluate] [1/3] ep_ret:[1772.7397] ep_len:[1000]\n",
      "[Evaluate] [2/3] ep_ret:[1759.1806] ep_len:[1000]\n",
      "[Evaluate] step:[190000/1000000][19.0%] time:00:37:16.\n",
      "[Evaluate] [0/3] ep_ret:[1786.6875] ep_len:[1000]\n",
      "[Evaluate] [1/3] ep_ret:[1792.5818] ep_len:[1000]\n",
      "[Evaluate] [2/3] ep_ret:[1826.7633] ep_len:[1000]\n",
      "[Evaluate] step:[200000/1000000][20.0%] time:00:39:19.\n",
      "[Evaluate] [0/3] ep_ret:[1957.1004] ep_len:[1000]\n",
      "[Evaluate] [1/3] ep_ret:[1952.7051] ep_len:[1000]\n",
      "[Evaluate] [2/3] ep_ret:[1955.5052] ep_len:[1000]\n",
      "[Evaluate] step:[210000/1000000][21.0%] time:00:41:22.\n",
      "[Evaluate] [0/3] ep_ret:[1995.4302] ep_len:[1000]\n",
      "[Evaluate] [1/3] ep_ret:[1988.5933] ep_len:[1000]\n",
      "[Evaluate] [2/3] ep_ret:[1992.1904] ep_len:[1000]\n",
      "[Evaluate] step:[220000/1000000][22.0%] time:00:43:24.\n",
      "[Evaluate] [0/3] ep_ret:[1916.3934] ep_len:[1000]\n",
      "[Evaluate] [1/3] ep_ret:[1918.6186] ep_len:[1000]\n",
      "[Evaluate] [2/3] ep_ret:[1931.7064] ep_len:[1000]\n",
      "[Evaluate] step:[230000/1000000][23.0%] time:00:45:27.\n",
      "[Evaluate] [0/3] ep_ret:[1989.8645] ep_len:[1000]\n",
      "[Evaluate] [1/3] ep_ret:[2002.5580] ep_len:[1000]\n",
      "[Evaluate] [2/3] ep_ret:[1999.5877] ep_len:[1000]\n",
      "[Evaluate] step:[240000/1000000][24.0%] time:00:47:29.\n",
      "[Evaluate] [0/3] ep_ret:[2259.4227] ep_len:[1000]\n",
      "[Evaluate] [1/3] ep_ret:[2242.8086] ep_len:[1000]\n",
      "[Evaluate] [2/3] ep_ret:[2249.3441] ep_len:[1000]\n",
      "[Evaluate] step:[250000/1000000][25.0%] time:00:49:32.\n",
      "[Evaluate] [0/3] ep_ret:[2209.2322] ep_len:[1000]\n",
      "[Evaluate] [1/3] ep_ret:[2212.8604] ep_len:[1000]\n",
      "[Evaluate] [2/3] ep_ret:[2209.5458] ep_len:[1000]\n",
      "[Evaluate] step:[260000/1000000][26.0%] time:00:51:35.\n",
      "[Evaluate] [0/3] ep_ret:[2403.1664] ep_len:[1000]\n",
      "[Evaluate] [1/3] ep_ret:[2401.8044] ep_len:[1000]\n",
      "[Evaluate] [2/3] ep_ret:[2407.9633] ep_len:[1000]\n",
      "[Evaluate] step:[270000/1000000][27.0%] time:00:53:37.\n",
      "[Evaluate] [0/3] ep_ret:[2414.2949] ep_len:[1000]\n",
      "[Evaluate] [1/3] ep_ret:[2414.6370] ep_len:[1000]\n",
      "[Evaluate] [2/3] ep_ret:[2403.3542] ep_len:[1000]\n",
      "[Evaluate] step:[280000/1000000][28.0%] time:00:55:39.\n",
      "[Evaluate] [0/3] ep_ret:[2398.8604] ep_len:[1000]\n",
      "[Evaluate] [1/3] ep_ret:[2393.4999] ep_len:[1000]\n",
      "[Evaluate] [2/3] ep_ret:[2401.0012] ep_len:[1000]\n",
      "[Evaluate] step:[290000/1000000][29.0%] time:00:57:41.\n",
      "[Evaluate] [0/3] ep_ret:[587.3409] ep_len:[1000]\n",
      "[Evaluate] [1/3] ep_ret:[494.2592] ep_len:[1000]\n",
      "[Evaluate] [2/3] ep_ret:[645.2794] ep_len:[1000]\n",
      "[Evaluate] step:[300000/1000000][30.0%] time:00:59:44.\n",
      "[Evaluate] [0/3] ep_ret:[1567.5285] ep_len:[1000]\n",
      "[Evaluate] [1/3] ep_ret:[1534.9439] ep_len:[1000]\n",
      "[Evaluate] [2/3] ep_ret:[1626.0583] ep_len:[1000]\n",
      "[Evaluate] step:[310000/1000000][31.0%] time:01:01:47.\n",
      "[Evaluate] [0/3] ep_ret:[2458.9723] ep_len:[1000]\n",
      "[Evaluate] [1/3] ep_ret:[2497.3552] ep_len:[1000]\n",
      "[Evaluate] [2/3] ep_ret:[2485.6810] ep_len:[1000]\n",
      "[Evaluate] step:[320000/1000000][32.0%] time:01:03:49.\n",
      "[Evaluate] [0/3] ep_ret:[2523.5774] ep_len:[1000]\n",
      "[Evaluate] [1/3] ep_ret:[2520.4945] ep_len:[1000]\n",
      "[Evaluate] [2/3] ep_ret:[2463.8150] ep_len:[1000]\n",
      "[Evaluate] step:[330000/1000000][33.0%] time:01:05:51.\n",
      "[Evaluate] [0/3] ep_ret:[2417.4304] ep_len:[1000]\n",
      "[Evaluate] [1/3] ep_ret:[2383.9072] ep_len:[1000]\n",
      "[Evaluate] [2/3] ep_ret:[2422.6076] ep_len:[1000]\n",
      "[Evaluate] step:[340000/1000000][34.0%] time:01:07:53.\n",
      "[Evaluate] [0/3] ep_ret:[2499.5442] ep_len:[1000]\n",
      "[Evaluate] [1/3] ep_ret:[2527.3708] ep_len:[1000]\n",
      "[Evaluate] [2/3] ep_ret:[2560.4222] ep_len:[1000]\n",
      "[Evaluate] step:[350000/1000000][35.0%] time:01:09:55.\n",
      "[Evaluate] [0/3] ep_ret:[2548.5785] ep_len:[1000]\n",
      "[Evaluate] [1/3] ep_ret:[2540.1617] ep_len:[1000]\n",
      "[Evaluate] [2/3] ep_ret:[2492.8691] ep_len:[1000]\n",
      "[Evaluate] step:[360000/1000000][36.0%] time:01:11:58.\n",
      "[Evaluate] [0/3] ep_ret:[2653.4914] ep_len:[1000]\n",
      "[Evaluate] [1/3] ep_ret:[2607.3016] ep_len:[1000]\n",
      "[Evaluate] [2/3] ep_ret:[2473.6106] ep_len:[1000]\n",
      "[Evaluate] step:[370000/1000000][37.0%] time:01:14:00.\n",
      "[Evaluate] [0/3] ep_ret:[2647.0878] ep_len:[1000]\n",
      "[Evaluate] [1/3] ep_ret:[2648.1803] ep_len:[1000]\n",
      "[Evaluate] [2/3] ep_ret:[2644.0117] ep_len:[1000]\n",
      "[Evaluate] step:[380000/1000000][38.0%] time:01:16:02.\n",
      "[Evaluate] [0/3] ep_ret:[2659.6804] ep_len:[1000]\n",
      "[Evaluate] [1/3] ep_ret:[2656.3678] ep_len:[1000]\n",
      "[Evaluate] [2/3] ep_ret:[2666.7661] ep_len:[1000]\n",
      "[Evaluate] step:[390000/1000000][39.0%] time:01:18:04.\n",
      "[Evaluate] [0/3] ep_ret:[2683.0951] ep_len:[1000]\n",
      "[Evaluate] [1/3] ep_ret:[2702.2153] ep_len:[1000]\n",
      "[Evaluate] [2/3] ep_ret:[2689.2801] ep_len:[1000]\n",
      "[Evaluate] step:[400000/1000000][40.0%] time:01:20:06.\n",
      "[Evaluate] [0/3] ep_ret:[2646.8930] ep_len:[1000]\n",
      "[Evaluate] [1/3] ep_ret:[2692.1843] ep_len:[1000]\n",
      "[Evaluate] [2/3] ep_ret:[2702.8216] ep_len:[1000]\n",
      "[Evaluate] step:[410000/1000000][41.0%] time:01:22:08.\n",
      "[Evaluate] [0/3] ep_ret:[2633.6645] ep_len:[1000]\n",
      "[Evaluate] [1/3] ep_ret:[2739.5635] ep_len:[1000]\n",
      "[Evaluate] [2/3] ep_ret:[2711.9052] ep_len:[1000]\n",
      "[Evaluate] step:[420000/1000000][42.0%] time:01:24:11.\n",
      "[Evaluate] [0/3] ep_ret:[2670.5388] ep_len:[1000]\n",
      "[Evaluate] [1/3] ep_ret:[2646.2296] ep_len:[1000]\n",
      "[Evaluate] [2/3] ep_ret:[2654.7001] ep_len:[1000]\n",
      "[Evaluate] step:[430000/1000000][43.0%] time:01:26:13.\n",
      "[Evaluate] [0/3] ep_ret:[2673.3065] ep_len:[1000]\n",
      "[Evaluate] [1/3] ep_ret:[2661.3728] ep_len:[1000]\n",
      "[Evaluate] [2/3] ep_ret:[2658.5350] ep_len:[1000]\n",
      "[Evaluate] step:[440000/1000000][44.0%] time:01:28:15.\n",
      "[Evaluate] [0/3] ep_ret:[2783.0507] ep_len:[1000]\n",
      "[Evaluate] [1/3] ep_ret:[2634.6169] ep_len:[1000]\n",
      "[Evaluate] [2/3] ep_ret:[2765.4374] ep_len:[1000]\n",
      "[Evaluate] step:[450000/1000000][45.0%] time:01:30:17.\n",
      "[Evaluate] [0/3] ep_ret:[2499.5819] ep_len:[1000]\n",
      "[Evaluate] [1/3] ep_ret:[2504.5552] ep_len:[1000]\n",
      "[Evaluate] [2/3] ep_ret:[2497.6502] ep_len:[1000]\n",
      "[Evaluate] step:[460000/1000000][46.0%] time:01:32:19.\n",
      "[Evaluate] [0/3] ep_ret:[2793.8538] ep_len:[1000]\n",
      "[Evaluate] [1/3] ep_ret:[2795.3619] ep_len:[1000]\n",
      "[Evaluate] [2/3] ep_ret:[2791.1349] ep_len:[1000]\n",
      "[Evaluate] step:[470000/1000000][47.0%] time:01:34:21.\n",
      "[Evaluate] [0/3] ep_ret:[2660.5879] ep_len:[1000]\n",
      "[Evaluate] [1/3] ep_ret:[2651.9331] ep_len:[1000]\n",
      "[Evaluate] [2/3] ep_ret:[2527.0478] ep_len:[1000]\n",
      "[Evaluate] step:[480000/1000000][48.0%] time:01:36:23.\n",
      "[Evaluate] [0/3] ep_ret:[1056.4289] ep_len:[1000]\n",
      "[Evaluate] [1/3] ep_ret:[1032.6122] ep_len:[1000]\n",
      "[Evaluate] [2/3] ep_ret:[1824.1081] ep_len:[1000]\n",
      "[Evaluate] step:[490000/1000000][49.0%] time:01:38:26.\n",
      "[Evaluate] [0/3] ep_ret:[2794.5479] ep_len:[1000]\n",
      "[Evaluate] [1/3] ep_ret:[2715.1633] ep_len:[1000]\n",
      "[Evaluate] [2/3] ep_ret:[2681.6904] ep_len:[1000]\n",
      "[Evaluate] step:[500000/1000000][50.0%] time:01:40:28.\n",
      "[Evaluate] [0/3] ep_ret:[2853.4560] ep_len:[1000]\n",
      "[Evaluate] [1/3] ep_ret:[2866.1164] ep_len:[1000]\n",
      "[Evaluate] [2/3] ep_ret:[2865.8869] ep_len:[1000]\n",
      "[Evaluate] step:[510000/1000000][51.0%] time:01:42:30.\n",
      "[Evaluate] [0/3] ep_ret:[2718.9907] ep_len:[1000]\n",
      "[Evaluate] [1/3] ep_ret:[2781.8737] ep_len:[1000]\n",
      "[Evaluate] [2/3] ep_ret:[2480.8257] ep_len:[1000]\n",
      "[Evaluate] step:[520000/1000000][52.0%] time:01:44:32.\n",
      "[Evaluate] [0/3] ep_ret:[1664.1726] ep_len:[1000]\n",
      "[Evaluate] [1/3] ep_ret:[1412.9994] ep_len:[1000]\n",
      "[Evaluate] [2/3] ep_ret:[2522.3505] ep_len:[1000]\n",
      "[Evaluate] step:[530000/1000000][53.0%] time:01:46:35.\n",
      "[Evaluate] [0/3] ep_ret:[2870.8879] ep_len:[1000]\n",
      "[Evaluate] [1/3] ep_ret:[1154.7253] ep_len:[1000]\n",
      "[Evaluate] [2/3] ep_ret:[2917.2929] ep_len:[1000]\n",
      "[Evaluate] step:[540000/1000000][54.0%] time:01:48:37.\n",
      "[Evaluate] [0/3] ep_ret:[2694.9652] ep_len:[1000]\n",
      "[Evaluate] [1/3] ep_ret:[856.4069] ep_len:[1000]\n",
      "[Evaluate] [2/3] ep_ret:[1556.0985] ep_len:[778]\n",
      "[Evaluate] step:[550000/1000000][55.0%] time:01:50:37.\n",
      "[Evaluate] [0/3] ep_ret:[2822.4934] ep_len:[1000]\n",
      "[Evaluate] [1/3] ep_ret:[2803.2757] ep_len:[1000]\n",
      "[Evaluate] [2/3] ep_ret:[2920.8928] ep_len:[1000]\n",
      "[Evaluate] step:[560000/1000000][56.0%] time:01:52:39.\n",
      "[Evaluate] [0/3] ep_ret:[2382.2731] ep_len:[1000]\n",
      "[Evaluate] [1/3] ep_ret:[2655.5802] ep_len:[1000]\n",
      "[Evaluate] [2/3] ep_ret:[2304.4036] ep_len:[1000]\n",
      "[Evaluate] step:[570000/1000000][57.0%] time:01:54:41.\n",
      "[Evaluate] [0/3] ep_ret:[2616.9673] ep_len:[1000]\n",
      "[Evaluate] [1/3] ep_ret:[2607.6791] ep_len:[1000]\n",
      "[Evaluate] [2/3] ep_ret:[2648.4836] ep_len:[1000]\n",
      "[Evaluate] step:[580000/1000000][58.0%] time:01:56:43.\n",
      "[Evaluate] [0/3] ep_ret:[2868.1858] ep_len:[1000]\n",
      "[Evaluate] [1/3] ep_ret:[2818.0191] ep_len:[1000]\n",
      "[Evaluate] [2/3] ep_ret:[922.7233] ep_len:[1000]\n",
      "[Evaluate] step:[590000/1000000][59.0%] time:01:58:45.\n",
      "[Evaluate] [0/3] ep_ret:[2932.6491] ep_len:[1000]\n",
      "[Evaluate] [1/3] ep_ret:[2919.4883] ep_len:[1000]\n",
      "[Evaluate] [2/3] ep_ret:[2920.4296] ep_len:[1000]\n",
      "[Evaluate] step:[600000/1000000][60.0%] time:02:00:47.\n",
      "[Evaluate] [0/3] ep_ret:[2795.9890] ep_len:[1000]\n",
      "[Evaluate] [1/3] ep_ret:[2188.8684] ep_len:[1000]\n",
      "[Evaluate] [2/3] ep_ret:[2608.4842] ep_len:[1000]\n",
      "[Evaluate] step:[610000/1000000][61.0%] time:02:02:50.\n",
      "[Evaluate] [0/3] ep_ret:[2754.4849] ep_len:[1000]\n",
      "[Evaluate] [1/3] ep_ret:[2770.4894] ep_len:[1000]\n",
      "[Evaluate] [2/3] ep_ret:[2246.9946] ep_len:[1000]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-1f5f814cc493>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;31m# Get action\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mstart_steps\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_action\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdeterministic\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maction_space\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-a79a60358622>\u001b[0m in \u001b[0;36mget_action\u001b[0;34m(model, sess, o, deterministic)\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_action\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdeterministic\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m     \u001b[0mact_op\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'mu'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdeterministic\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'pi'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 144\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mact_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'o_ph'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    145\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"SAC model ready.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/RL_tfv1/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    948\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 950\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    951\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    952\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/RL_tfv1/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1171\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1172\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1173\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1174\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1175\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/RL_tfv1/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1348\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1349\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1350\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1351\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1352\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/RL_tfv1/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1354\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1355\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1356\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1357\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1358\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/RL_tfv1/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1339\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1340\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1341\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1342\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1343\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/RL_tfv1/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1427\u001b[0m     return tf_session.TF_SessionRun_wrapper(\n\u001b[1;32m   1428\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1429\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1430\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1431\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "o,ep_ret,ep_len = env.reset(),0,0\n",
    "for t in range(int(total_steps)):\n",
    "    zero_to_one = (t/total_steps)\n",
    "    one_to_zero = 1.0-zero_to_one\n",
    "    esec = time.time()-start_time\n",
    "    \n",
    "    # Get action \n",
    "    if t > start_steps: a = get_action(model,sess,o,deterministic=False)\n",
    "    else: a = env.action_space.sample()\n",
    "        \n",
    "    # Step the env\n",
    "    o2,r,d,_ = env.step(a)\n",
    "    ep_ret += r\n",
    "    ep_len += 1\n",
    "    d = False if ep_len==max_ep_len_train else d # ignore done if it maxed out \n",
    "    \n",
    "    # Store experience to replay buffers\n",
    "    replay_buffer.store(o, a, r, o2, d) # save obs, action, reward, next obs\n",
    "    replay_buffer_short.store(o, a, r, o2, d) # save obs, action, reward, next obs\n",
    "    o = o2 # easy to overlook\n",
    "    \n",
    "    # End of trajectory handling - reset env\n",
    "    if d or (ep_len == max_ep_len_train):\n",
    "        o, ep_ret, ep_len = env.reset(), 0, 0\n",
    "\n",
    "    # Update\n",
    "    if (t>=start_steps) and (t%update_every == 0):\n",
    "        for _ in range(update_count):\n",
    "            batch = replay_buffer.sample_batch(batch_size//2) \n",
    "            batch_short = replay_buffer_short.sample_batch(batch_size//2) \n",
    "            feed_dict = {model['o_ph']: np.concatenate((batch['obs1'],batch_short['obs1'])),\n",
    "                         model['o2_ph']: np.concatenate((batch['obs2'],batch_short['obs2'])),\n",
    "                         model['a_ph']: np.concatenate((batch['acts'],batch_short['acts'])),\n",
    "                         model['r_ph']: np.concatenate((batch['rews'],batch_short['rews'])),\n",
    "                         model['d_ph']: np.concatenate((batch['done'],batch_short['done']))\n",
    "                        }\n",
    "            outs = sess.run(step_ops,feed_dict=feed_dict) # train \n",
    "            q1_val, q2_val = outs[4],outs[5],outs[6],outs[7],outs[8], outs[9], outs[10]\n",
    "\n",
    "    # Evaluate\n",
    "    if (((t+1)%evaluate_every) == 0): \n",
    "        print (\"[Evaluate] step:[%d/%d][%.1f%%] time:%s.\"%\n",
    "               (t+1,total_steps,zero_to_one*100,\n",
    "                time.strftime(\"%H:%M:%S\", time.gmtime(time.time()-start_time)))\n",
    "              )\n",
    "        if(t>=start_steps):\n",
    "            # Tensorboard\n",
    "            sess.run(pi_loss_update_op, feed_dict=feed_dict)\n",
    "            sess.run(val_loss_update_op, feed_dict=feed_dict)\n",
    "            summary_value = sess.run(summary, feed_dict=feed_dict)\n",
    "            summary_writer.add_summary(summary_value, global_step=t)\n",
    "\n",
    "        for eval_idx in range(num_eval): \n",
    "            o,d,ep_ret,ep_len = test_env.reset(),False,0,0\n",
    "            _ = test_env.render(mode='human') \n",
    "            while not(d or (ep_len == max_ep_len_test)):\n",
    "                a = get_action(model,sess,o,deterministic=True)\n",
    "                o,r,d,_ = test_env.step(a)\n",
    "                _ = test_env.render(mode='human') \n",
    "                ep_ret += r # compute return \n",
    "                ep_len += 1\n",
    "            print (\"[Evaluate] [%d/%d] ep_ret:[%.4f] ep_len:[%d]\"\n",
    "                %(eval_idx,num_eval,ep_ret,ep_len))\n",
    "    \n",
    "print (\"Done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(q_vars)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Close "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()\n",
    "test_env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gym.logger.set_level(40)\n",
    "env_name = 'AntBulletEnv-v0'\n",
    "test_env = gym.make(env_name)\n",
    "_ = test_env.render(mode='human') # enable rendering on test_env\n",
    "_ = test_env.reset()\n",
    "for _ in range(3): # dummy run for proper rendering \n",
    "    a = test_env.action_space.sample()\n",
    "    o,r,d,_ = test_env.step(a)\n",
    "    time.sleep(0.01)\n",
    "print (\"[%s] ready.\"%(env_name))\n",
    "o,d,ep_ret,ep_len = test_env.reset(),False,0,0\n",
    "_ = test_env.render(mode='human') \n",
    "while not(d or (ep_len == max_ep_len_test)):\n",
    "    a = get_action(model,sess,o,deterministic=True)\n",
    "    o,r,d,_ = test_env.step(a)\n",
    "    _ = test_env.render(mode='human') \n",
    "    ep_ret += r # compute return \n",
    "    ep_len += 1\n",
    "print (\"[Evaluate] ep_ret:[%.4f] ep_len:[%d]\"\n",
    "    %(ep_ret,ep_len))\n",
    "test_env.close() # close env "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Video\n",
    "Video('../vid/SAC_PyBullet_Ant.mp4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "_draft": {
   "nbviewer_url": "https://gist.github.com/3f583727383beb34adca11b6dfea5d4e"
  },
  "gist": {
   "data": {
    "description": "Self-contained SAC on PyBullet Ant",
    "public": true
   },
   "id": "3f583727383beb34adca11b6dfea5d4e"
  },
  "interpreter": {
   "hash": "d6bfe750365b01d3f946bc60445dd9d4b06e4702844b6c71fde1d9a7dc656614"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}