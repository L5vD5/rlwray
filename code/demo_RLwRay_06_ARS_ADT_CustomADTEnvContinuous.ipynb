{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ARS with CustomADTEnvContinuous"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Packaged loaded. TF version is [1.15.0].\n"
     ]
    }
   ],
   "source": [
    "import datetime,gym,time,os,psutil,ray\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from util import gpu_sess,suppress_tf_warning,tic,toc,open_txt,write_txt,OnlineMeanVariance\n",
    "from ars import create_ars_model,get_noises_from_weights,save_ars_model,restore_ars_model\n",
    "np.set_printoptions(precision=2)\n",
    "suppress_tf_warning() # suppress warning \n",
    "gym.logger.set_level(40) # gym logger \n",
    "\n",
    "from episci.environment_wrappers.tactical_action_adt_env_continuous import CustomADTEnvContinuous\n",
    "from episci.agents.utils.constants import Agents, RewardType\n",
    "print (\"Packaged loaded. TF version is [%s].\"%(tf.__version__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_name = 'ars_adt_cont'\n",
    "n_cpu = 51\n",
    "n_workers = 50\n",
    "total_steps,evaluate_every,print_every = 5000,5,1\n",
    "ep_len_rollout = 15000\n",
    "hdims,actv,out_actv = [64,16],tf.nn.relu,tf.nn.tanh\n",
    "# alpha:stepsize / nu:exploration std / b: elite set size\n",
    "alpha,nu,b = 0.0075,0.01,(n_workers//5)\n",
    "seed = 0\n",
    "# Train\n",
    "action_length = 5 # 50/5 = 10HZ\n",
    "red_list_train = [\n",
    "    Agents.SPOT_RANDOM,\n",
    "    Agents.EXPERT_SYSTEM\n",
    "]\n",
    "# Evaluation\n",
    "red_list_eval = [\n",
    "    Agents.ZOMBIE, \n",
    "    Agents.ROSIE, \n",
    "    Agents.BUD, \n",
    "    Agents.BUD_FSM, \n",
    "    Agents.EXPERT_SYSTEM_TRIAL_2, \n",
    "    Agents.EXPERT_SYSTEM_TRIAL_3_SCRIMMAGE_4, \n",
    "    Agents.EXPERT_SYSTEM\n",
    "]*n_workers\n",
    "red_list_eval = red_list_eval[:n_workers]\n",
    "num_eval,max_ep_len_eval = len(red_list_eval),15e3 # evaluation\n",
    "# Restore\n",
    "npz_path = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[../log/ars_adt_cont/log_Jul-20-2020-23:26:45.txt] created.\n"
     ]
    }
   ],
   "source": [
    "txt_path = '../log/%s/log_%s.txt'%(\n",
    "    exp_name,\n",
    "    datetime.datetime.now().strftime(\"%b-%d-%Y-%H:%M:%S\"))\n",
    "f = open_txt(txt_path)\n",
    "print (\"[%s] created.\"%(txt_path))\n",
    "time.sleep(1) # wait "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_env(red_distribution=None):\n",
    "    from episci.environment_wrappers.tactical_action_adt_env_continuous import CustomADTEnvContinuous\n",
    "    from episci.agents.utils.constants import Agents, RewardType\n",
    "    env_config = {\n",
    "        \"red_distribution\": red_distribution,\n",
    "        \"reward_type\": RewardType.SHAPED\n",
    "    }\n",
    "    return CustomADTEnvContinuous(env_config,action_length=action_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Worker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RolloutWorkerClass(object):\n",
    "    \"\"\"\n",
    "    Worker without RAY (for update purposes)\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 hdims=[64]*2,actv=tf.nn.relu,out_actv=tf.nn.tanh,\n",
    "                 seed=1):\n",
    "        self.seed = seed\n",
    "        from util import suppress_tf_warning\n",
    "        suppress_tf_warning() # suppress TF warnings\n",
    "        self.env = get_env()\n",
    "        odim,adim = self.env.observation_space.shape[0],self.env.action_space.shape[0]\n",
    "        self.odim,self.adim = odim,adim\n",
    "        # Observation normalization\n",
    "        self.obs_mu = np.zeros(self.odim)\n",
    "        self.obs_std = np.ones(self.odim)\n",
    "        # ARS model \n",
    "        self.model,self.sess = create_ars_model(\n",
    "            odim=self.odim,adim=self.adim,hdims=hdims,\n",
    "            actv=actv,out_actv=out_actv)\n",
    "        # Initialize model \n",
    "        tf.set_random_seed(self.seed)\n",
    "        np.random.seed(self.seed)\n",
    "        self.sess.run(tf.global_variables_initializer())\n",
    "        # Flag to initialize assign operations for 'set_weights()'\n",
    "        self.FIRST_SET_FLAG = True\n",
    "    def set_observation_stats(self,obs_mu,obs_std):\n",
    "        self.obs_mu = obs_mu\n",
    "        self.obs_std = obs_std\n",
    "    def get_action(self,o):\n",
    "        obs_std = self.obs_std\n",
    "        obs_std[obs_std<1e-6] = np.inf\n",
    "        nzd_o = (o-self.obs_mu)/obs_std\n",
    "        return self.sess.run(\n",
    "            self.model['mu'],feed_dict={self.model['o_ph']:nzd_o.reshape(1,-1)})[0]\n",
    "    def get_weights(self):\n",
    "        weight_vals = self.sess.run(self.model['main_vars'])\n",
    "        return weight_vals\n",
    "    def set_weights(self,weight_vals):\n",
    "        if self.FIRST_SET_FLAG:\n",
    "            self.FIRST_SET_FLAG = False\n",
    "            self.assign_placeholders = []\n",
    "            self.assign_ops = []\n",
    "            for w_idx,weight_tf_var in enumerate(self.model['main_vars']):\n",
    "                a = weight_tf_var\n",
    "                assign_placeholder = tf.placeholder(a.dtype, shape=a.get_shape())\n",
    "                assign_op = a.assign(assign_placeholder)\n",
    "                self.assign_placeholders.append(assign_placeholder)\n",
    "                self.assign_ops.append(assign_op)\n",
    "        for w_idx,weight_tf_var in enumerate(self.model['main_vars']):\n",
    "            self.sess.run(self.assign_ops[w_idx],\n",
    "                          {self.assign_placeholders[w_idx]:weight_vals[w_idx]})\n",
    "            \n",
    "@ray.remote\n",
    "class RayRolloutWorkerClass(object):\n",
    "    \"\"\"\n",
    "    Rollout Worker with RAY\n",
    "    \"\"\"\n",
    "    def __init__(self,worker_id=0,\n",
    "                 hdims=[128],actv=tf.nn.relu,out_actv=tf.nn.tanh,\n",
    "                 ep_len_rollout=15000):\n",
    "        self.worker_id = worker_id\n",
    "        self.ep_len_rollout = ep_len_rollout\n",
    "        from util import suppress_tf_warning\n",
    "        suppress_tf_warning() # suppress TF warnings\n",
    "        self.env = get_env()\n",
    "        odim,adim = self.env.observation_space.shape[0],self.env.action_space.shape[0]\n",
    "        self.odim,self.adim = odim,adim\n",
    "        # Observation normalization\n",
    "        self.obs_mu = np.zeros(self.odim)\n",
    "        self.obs_std = np.ones(self.odim)\n",
    "        # ARS model \n",
    "        self.model,self.sess = create_ars_model(\n",
    "            odim=self.odim,adim=self.adim,hdims=hdims,\n",
    "            actv=actv,out_actv=out_actv)\n",
    "        # Flag to initialize assign operations for 'set_weights()'\n",
    "        self.FIRST_SET_FLAG = True        \n",
    "    def set_observation_stats(self,obs_mu,obs_std):\n",
    "        self.obs_mu = np.copy(obs_mu) # call by value\n",
    "        self.obs_std = np.copy(obs_std) # call by value\n",
    "    def get_action(self,o):\n",
    "        obs_std = self.obs_std\n",
    "        obs_std[obs_std<1e-6] = np.inf\n",
    "        nzd_o = (o-self.obs_mu)/obs_std # use whitened observation \n",
    "        return self.sess.run(\n",
    "            self.model['mu'],feed_dict={self.model['o_ph']:nzd_o.reshape(1,-1)})[0]\n",
    "    def set_weights(self,weight_vals,noise_vals,noise_sign=+1):\n",
    "        if self.FIRST_SET_FLAG:\n",
    "            self.FIRST_SET_FLAG = False\n",
    "            self.assign_placeholders = []\n",
    "            self.assign_ops = []\n",
    "            for w_idx,weight_tf_var in enumerate(self.model['main_vars']):\n",
    "                a = weight_tf_var\n",
    "                assign_placeholder = tf.placeholder(a.dtype, shape=a.get_shape())\n",
    "                assign_op = a.assign(assign_placeholder)\n",
    "                self.assign_placeholders.append(assign_placeholder)\n",
    "                self.assign_ops.append(assign_op)\n",
    "        for w_idx,weight_tf_var in enumerate(self.model['main_vars']):\n",
    "            self.sess.run(self.assign_ops[w_idx],\n",
    "                          {self.assign_placeholders[w_idx]:\n",
    "                           weight_vals[w_idx]+noise_sign*noise_vals[w_idx]})\n",
    "    def rollout(self,\n",
    "                red_list=[Agents.SPOT_RANDOM,Agents.EXPERT_SYSTEM]):\n",
    "        \"\"\"\n",
    "        Rollout\n",
    "        \"\"\"\n",
    "        obs_buffer,obs_cnt = np.zeros((len(red_list)*self.ep_len_rollout,self.odim)),0\n",
    "        for r_idx,red in enumerate(red_list): # for each red policy\n",
    "            # Specify red policy\n",
    "            self.o,r_sum,n_step = self.env.reset(red=red),0,0 \n",
    "            for t in range(self.ep_len_rollout):\n",
    "                self.a = self.get_action(self.o) \n",
    "                self.o2,self.r,self.d,_ = self.env.step(self.a)\n",
    "                # Save next state \n",
    "                self.o = self.o2\n",
    "                # Accumulate reward\n",
    "                r_sum += self.r\n",
    "                n_step += 1\n",
    "                # Stack observation\n",
    "                obs_buffer[obs_cnt,:] = self.o\n",
    "                obs_cnt += 1\n",
    "                if self.d: \n",
    "                    break \n",
    "        # Compute the average return and steps \n",
    "        r_avg = r_sum / len(red_list)\n",
    "        n_step_avg = n_step / len(red_list)\n",
    "        obs_buffer = obs_buffer[:obs_cnt,:] # trim observation buffer \n",
    "        return r_avg,n_step_avg,obs_buffer\n",
    "    \n",
    "    def evaluate(self,red=None):\n",
    "        o,d,ep_ret,ep_len = self.env.reset(red=red),False,0,0\n",
    "        while not(d or (ep_len == self.ep_len_rollout)):\n",
    "            a = self.get_action(o)\n",
    "            o,r,d,_ = self.env.step(a)\n",
    "            ep_ret += r # compute return \n",
    "            ep_len += 1\n",
    "        blue_health,red_health = self.env.blue_health,self.env.red_health\n",
    "        eval_res = [ep_ret,ep_len,blue_health,red_health] # return / length / bluehealth / redhealth\n",
    "        return eval_res\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment Ready. odim:[55] adim:[4].\n"
     ]
    }
   ],
   "source": [
    "env = get_env()\n",
    "adim,odim = env.action_space.shape[0],env.observation_space.shape[0]\n",
    "print (\"Environment Ready. odim:[%d] adim:[%d].\"%(odim,adim))\n",
    "write_txt(f,\"Environment Ready. odim:[%d] adim:[%d].\"%(odim,adim),\n",
    "          ADD_NEWLINE=True,DO_PRINT=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observation online normalizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "mv = OnlineMeanVariance()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize Workers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-07-20 23:26:46,203\tINFO resource_spec.py:212 -- Starting Ray with 138.92 GiB memory available for workers and up to 63.53 GiB for objects. You can adjust these settings with ray.init(memory=<bytes>, object_store_memory=<bytes>).\n",
      "2020-07-20 23:26:46,441\tWARNING services.py:923 -- Redis failed to start, retrying now.\n",
      "2020-07-20 23:26:46,656\tINFO services.py:1165 -- View the Ray dashboard at \u001b[1m\u001b[32mlocalhost:8265\u001b[39m\u001b[22m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAY initialized with [51] cpus and [50] workers.\n"
     ]
    }
   ],
   "source": [
    "ray.init(num_cpus=n_cpu)\n",
    "tf.reset_default_graph()\n",
    "R = RolloutWorkerClass(hdims=hdims,actv=actv,out_actv=out_actv,seed=seed)\n",
    "workers = [RayRolloutWorkerClass.remote(\n",
    "    worker_id=i,hdims=hdims,actv=actv,out_actv=out_actv,\n",
    "    ep_len_rollout=ep_len_rollout)\n",
    "           for i in range(n_workers)]\n",
    "print (\"RAY initialized with [%d] cpus and [%d] workers.\"%\n",
    "       (n_cpu,n_workers))\n",
    "write_txt(f,\"RAY initialized with [%d] cpus and [%d] workers.\"%(n_cpu,n_workers),\n",
    "          ADD_NEWLINE=True,DO_PRINT=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Restore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "if npz_path:\n",
    "    restore_ars_model(npz_path,R,VERBOSE=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=81640)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=81640)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=81640)\u001b[0m      JSBSim Flight Dynamics Model v1.1.0.dev1 Jul 11 2020 05:35:14\n",
      "\u001b[2m\u001b[36m(pid=81664)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=81664)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=81664)\u001b[0m      JSBSim Flight Dynamics Model v1.1.0.dev1 Jul 11 2020 05:35:14\n",
      "\u001b[2m\u001b[36m(pid=81672)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=81672)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=81672)\u001b[0m      JSBSim Flight Dynamics Model v1.1.0.dev1 Jul 11 2020 05:35:14\n",
      "\u001b[2m\u001b[36m(pid=81667)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=81667)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=81667)\u001b[0m      JSBSim Flight Dynamics Model v1.1.0.dev1 Jul 11 2020 05:35:14\n",
      "\u001b[2m\u001b[36m(pid=81641)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=81641)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=81641)\u001b[0m      JSBSim Flight Dynamics Model v1.1.0.dev1 Jul 11 2020 05:35:14\n",
      "\u001b[2m\u001b[36m(pid=81677)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=81677)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=81677)\u001b[0m      JSBSim Flight Dynamics Model v1.1.0.dev1 Jul 11 2020 05:35:14\n",
      "\u001b[2m\u001b[36m(pid=81651)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=81651)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=81651)\u001b[0m      JSBSim Flight Dynamics Model v1.1.0.dev1 Jul 11 2020 05:35:14\n",
      "\u001b[2m\u001b[36m(pid=81686)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=81686)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=81686)\u001b[0m      JSBSim Flight Dynamics Model v1.1.0.dev1 Jul 11 2020 05:35:14\n",
      "\u001b[2m\u001b[36m(pid=81666)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=81666)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=81666)\u001b[0m      JSBSim Flight Dynamics Model v1.1.0.dev1 Jul 11 2020 05:35:14\n",
      "\u001b[2m\u001b[36m(pid=81642)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=81642)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=81642)\u001b[0m      JSBSim Flight Dynamics Model v1.1.0.dev1 Jul 11 2020 05:35:14\n",
      "\u001b[2m\u001b[36m(pid=81652)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=81652)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=81652)\u001b[0m      JSBSim Flight Dynamics Model v1.1.0.dev1 Jul 11 2020 05:35:14\n",
      "\u001b[2m\u001b[36m(pid=81644)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=81644)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=81644)\u001b[0m      JSBSim Flight Dynamics Model v1.1.0.dev1 Jul 11 2020 05:35:14\n",
      "\u001b[2m\u001b[36m(pid=81656)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=81656)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=81656)\u001b[0m      JSBSim Flight Dynamics Model v1.1.0.dev1 Jul 11 2020 05:35:14\n",
      "\u001b[2m\u001b[36m(pid=81653)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=81653)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=81653)\u001b[0m      JSBSim Flight Dynamics Model v1.1.0.dev1 Jul 11 2020 05:35:14\n",
      "\u001b[2m\u001b[36m(pid=81650)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=81650)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=81650)\u001b[0m      JSBSim Flight Dynamics Model v1.1.0.dev1 Jul 11 2020 05:35:14\n",
      "\u001b[2m\u001b[36m(pid=81684)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=81684)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=81684)\u001b[0m      JSBSim Flight Dynamics Model v1.1.0.dev1 Jul 11 2020 05:35:14\n",
      "\u001b[2m\u001b[36m(pid=81659)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=81659)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=81659)\u001b[0m      JSBSim Flight Dynamics Model v1.1.0.dev1 Jul 11 2020 05:35:14\n",
      "\u001b[2m\u001b[36m(pid=81680)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=81680)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=81680)\u001b[0m      JSBSim Flight Dynamics Model v1.1.0.dev1 Jul 11 2020 05:35:14\n",
      "\u001b[2m\u001b[36m(pid=81670)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=81670)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=81670)\u001b[0m      JSBSim Flight Dynamics Model v1.1.0.dev1 Jul 11 2020 05:35:14\n",
      "\u001b[2m\u001b[36m(pid=81662)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=81662)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=81662)\u001b[0m      JSBSim Flight Dynamics Model v1.1.0.dev1 Jul 11 2020 05:35:14\n",
      "\u001b[2m\u001b[36m(pid=81676)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=81676)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=81676)\u001b[0m      JSBSim Flight Dynamics Model v1.1.0.dev1 Jul 11 2020 05:35:14\n",
      "\u001b[2m\u001b[36m(pid=81657)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=81657)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=81657)\u001b[0m      JSBSim Flight Dynamics Model v1.1.0.dev1 Jul 11 2020 05:35:14\n",
      "\u001b[2m\u001b[36m(pid=81655)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=81655)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=81655)\u001b[0m      JSBSim Flight Dynamics Model v1.1.0.dev1 Jul 11 2020 05:35:14\n",
      "\u001b[2m\u001b[36m(pid=81679)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=81679)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=81679)\u001b[0m      JSBSim Flight Dynamics Model v1.1.0.dev1 Jul 11 2020 05:35:14\n",
      "\u001b[2m\u001b[36m(pid=81649)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=81649)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=81649)\u001b[0m      JSBSim Flight Dynamics Model v1.1.0.dev1 Jul 11 2020 05:35:14\n",
      "\u001b[2m\u001b[36m(pid=81675)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=81675)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=81675)\u001b[0m      JSBSim Flight Dynamics Model v1.1.0.dev1 Jul 11 2020 05:35:14\n",
      "\u001b[2m\u001b[36m(pid=81661)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=81661)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=81661)\u001b[0m      JSBSim Flight Dynamics Model v1.1.0.dev1 Jul 11 2020 05:35:14\n",
      "\u001b[2m\u001b[36m(pid=81648)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=81648)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=81648)\u001b[0m      JSBSim Flight Dynamics Model v1.1.0.dev1 Jul 11 2020 05:35:14\n",
      "\u001b[2m\u001b[36m(pid=81647)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=81647)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=81647)\u001b[0m      JSBSim Flight Dynamics Model v1.1.0.dev1 Jul 11 2020 05:35:14\n",
      "\u001b[2m\u001b[36m(pid=81654)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=81654)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=81654)\u001b[0m      JSBSim Flight Dynamics Model v1.1.0.dev1 Jul 11 2020 05:35:14\n",
      "\u001b[2m\u001b[36m(pid=81639)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=81639)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=81639)\u001b[0m      JSBSim Flight Dynamics Model v1.1.0.dev1 Jul 11 2020 05:35:14\n",
      "\u001b[2m\u001b[36m(pid=81646)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=81646)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=81646)\u001b[0m      JSBSim Flight Dynamics Model v1.1.0.dev1 Jul 11 2020 05:35:14\n",
      "\u001b[2m\u001b[36m(pid=81668)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=81668)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=81668)\u001b[0m      JSBSim Flight Dynamics Model v1.1.0.dev1 Jul 11 2020 05:35:14\n",
      "\u001b[2m\u001b[36m(pid=81673)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=81673)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=81673)\u001b[0m      JSBSim Flight Dynamics Model v1.1.0.dev1 Jul 11 2020 05:35:14\n",
      "\u001b[2m\u001b[36m(pid=81643)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=81643)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=81643)\u001b[0m      JSBSim Flight Dynamics Model v1.1.0.dev1 Jul 11 2020 05:35:14\n",
      "\u001b[2m\u001b[36m(pid=81682)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=81682)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=81682)\u001b[0m      JSBSim Flight Dynamics Model v1.1.0.dev1 Jul 11 2020 05:35:14\n",
      "\u001b[2m\u001b[36m(pid=81645)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=81645)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=81645)\u001b[0m      JSBSim Flight Dynamics Model v1.1.0.dev1 Jul 11 2020 05:35:14\n",
      "\u001b[2m\u001b[36m(pid=81660)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=81660)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=81660)\u001b[0m      JSBSim Flight Dynamics Model v1.1.0.dev1 Jul 11 2020 05:35:14\n",
      "\u001b[2m\u001b[36m(pid=81671)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=81671)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=81671)\u001b[0m      JSBSim Flight Dynamics Model v1.1.0.dev1 Jul 11 2020 05:35:14\n",
      "\u001b[2m\u001b[36m(pid=81665)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=81665)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=81665)\u001b[0m      JSBSim Flight Dynamics Model v1.1.0.dev1 Jul 11 2020 05:35:14\n",
      "\u001b[2m\u001b[36m(pid=81689)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=81689)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=81689)\u001b[0m      JSBSim Flight Dynamics Model v1.1.0.dev1 Jul 11 2020 05:35:14\n",
      "\u001b[2m\u001b[36m(pid=81658)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=81658)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=81658)\u001b[0m      JSBSim Flight Dynamics Model v1.1.0.dev1 Jul 11 2020 05:35:14\n",
      "\u001b[2m\u001b[36m(pid=81687)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=81687)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=81687)\u001b[0m      JSBSim Flight Dynamics Model v1.1.0.dev1 Jul 11 2020 05:35:14\n",
      "\u001b[2m\u001b[36m(pid=81681)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=81681)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=81681)\u001b[0m      JSBSim Flight Dynamics Model v1.1.0.dev1 Jul 11 2020 05:35:14\n",
      "\u001b[2m\u001b[36m(pid=81683)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=81683)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=81683)\u001b[0m      JSBSim Flight Dynamics Model v1.1.0.dev1 Jul 11 2020 05:35:14\n",
      "\u001b[2m\u001b[36m(pid=81678)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=81678)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=81678)\u001b[0m      JSBSim Flight Dynamics Model v1.1.0.dev1 Jul 11 2020 05:35:14\n",
      "\u001b[2m\u001b[36m(pid=81685)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=81685)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=81685)\u001b[0m      JSBSim Flight Dynamics Model v1.1.0.dev1 Jul 11 2020 05:35:14\n",
      "\u001b[2m\u001b[36m(pid=81669)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=81669)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=81669)\u001b[0m      JSBSim Flight Dynamics Model v1.1.0.dev1 Jul 11 2020 05:35:14\n",
      "\u001b[2m\u001b[36m(pid=81674)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=81674)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=81674)\u001b[0m      JSBSim Flight Dynamics Model v1.1.0.dev1 Jul 11 2020 05:35:14\n",
      "\u001b[2m\u001b[36m(pid=81663)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=81663)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=81663)\u001b[0m      JSBSim Flight Dynamics Model v1.1.0.dev1 Jul 11 2020 05:35:14\n",
      "[0/5000] time:[day:[01] 00:06:43] max_ret:[50.84] max_ret_delta:[101.42] sigma_R:[37.73] \n",
      "[Eval. start] step:[1/5000][0.0%] #step:[8.7e+04] time:[day:[01] 00:06:43] ram:[22.8%].\n",
      " [0/50] [zombie] ep_ret:[33.0124] ep_len:[3001]. blue health:[1.00] red health:[0.69]\n",
      " [1/50] [rosie] ep_ret:[0.7313] ep_len:[3001]. blue health:[1.00] red health:[1.00]\n",
      " [2/50] [bud] ep_ret:[100.9168] ep_len:[1535]. blue health:[1.00] red health:[0.00]\n",
      " [3/50] [bud_fsm] ep_ret:[34.8104] ep_len:[2463]. blue health:[0.00] red health:[0.64]\n",
      " [4/50] [es_trial2] ep_ret:[18.0171] ep_len:[3001]. blue health:[1.00] red health:[0.82]\n",
      " [5/50] [es_trial3_scrimmage4] ep_ret:[-1.6324] ep_len:[3001]. blue health:[1.00] red health:[1.00]\n",
      " [6/50] [expert_system] ep_ret:[-101.0348] ep_len:[1392]. blue health:[0.00] red health:[1.00]\n",
      " [7/50] [zombie] ep_ret:[-2.6642] ep_len:[539]. blue health:[0.00] red health:[1.00]\n",
      " [8/50] [rosie] ep_ret:[31.8082] ep_len:[3001]. blue health:[1.00] red health:[0.69]\n",
      " [9/50] [bud] ep_ret:[100.1600] ep_len:[936]. blue health:[1.00] red health:[0.00]\n",
      " [10/50] [bud_fsm] ep_ret:[-2.3369] ep_len:[763]. blue health:[0.00] red health:[1.00]\n",
      " [11/50] [es_trial2] ep_ret:[17.1471] ep_len:[3001]. blue health:[0.97] red health:[0.80]\n",
      " [12/50] [es_trial3_scrimmage4] ep_ret:[-7.0623] ep_len:[3001]. blue health:[0.95] red health:[1.00]\n",
      " [13/50] [expert_system] ep_ret:[-100.3209] ep_len:[886]. blue health:[0.00] red health:[1.00]\n",
      " [14/50] [zombie] ep_ret:[66.1920] ep_len:[3001]. blue health:[1.00] red health:[0.37]\n",
      " [15/50] [rosie] ep_ret:[25.5515] ep_len:[3001]. blue health:[1.00] red health:[0.76]\n",
      " [16/50] [bud] ep_ret:[100.0376] ep_len:[1239]. blue health:[1.00] red health:[0.00]\n",
      " [17/50] [bud_fsm] ep_ret:[3.7764] ep_len:[916]. blue health:[0.00] red health:[0.94]\n",
      " [18/50] [es_trial2] ep_ret:[81.9916] ep_len:[3001]. blue health:[0.96] red health:[0.15]\n",
      " [19/50] [es_trial3_scrimmage4] ep_ret:[-100.4496] ep_len:[642]. blue health:[0.00] red health:[1.00]\n",
      " [20/50] [expert_system] ep_ret:[-100.6611] ep_len:[1573]. blue health:[0.00] red health:[1.00]\n",
      " [21/50] [zombie] ep_ret:[26.9669] ep_len:[3001]. blue health:[1.00] red health:[0.74]\n",
      " [22/50] [rosie] ep_ret:[23.0930] ep_len:[3001]. blue health:[1.00] red health:[0.78]\n",
      " [23/50] [bud] ep_ret:[-3.0853] ep_len:[3001]. blue health:[1.00] red health:[1.00]\n",
      " [24/50] [bud_fsm] ep_ret:[71.4870] ep_len:[3001]. blue health:[1.00] red health:[0.29]\n",
      " [25/50] [es_trial2] ep_ret:[101.6525] ep_len:[2664]. blue health:[1.00] red health:[0.00]\n",
      " [26/50] [es_trial3_scrimmage4] ep_ret:[43.0750] ep_len:[3001]. blue health:[0.99] red health:[0.56]\n",
      " [27/50] [expert_system] ep_ret:[-90.5128] ep_len:[2418]. blue health:[0.00] red health:[0.89]\n",
      " [28/50] [zombie] ep_ret:[101.1418] ep_len:[1626]. blue health:[1.00] red health:[0.00]\n",
      " [29/50] [rosie] ep_ret:[31.4849] ep_len:[3001]. blue health:[1.00] red health:[0.69]\n",
      " [30/50] [bud] ep_ret:[100.7585] ep_len:[1379]. blue health:[1.00] red health:[0.00]\n",
      " [31/50] [bud_fsm] ep_ret:[25.5733] ep_len:[3001]. blue health:[1.00] red health:[0.75]\n",
      " [32/50] [es_trial2] ep_ret:[100.3187] ep_len:[2012]. blue health:[1.00] red health:[0.00]\n",
      " [33/50] [es_trial3_scrimmage4] ep_ret:[-100.4717] ep_len:[675]. blue health:[0.00] red health:[1.00]\n",
      " [34/50] [expert_system] ep_ret:[29.2712] ep_len:[3001]. blue health:[1.00] red health:[0.70]\n",
      " [35/50] [zombie] ep_ret:[1.3224] ep_len:[3001]. blue health:[1.00] red health:[1.00]\n",
      " [36/50] [rosie] ep_ret:[-2.4350] ep_len:[506]. blue health:[0.00] red health:[1.00]\n",
      " [37/50] [bud] ep_ret:[-2.4111] ep_len:[754]. blue health:[0.00] red health:[1.00]\n",
      " [38/50] [bud_fsm] ep_ret:[-2.6463] ep_len:[1581]. blue health:[0.00] red health:[1.00]\n",
      " [39/50] [es_trial2] ep_ret:[101.2359] ep_len:[2352]. blue health:[1.00] red health:[0.00]\n",
      " [40/50] [es_trial3_scrimmage4] ep_ret:[-78.6656] ep_len:[1149]. blue health:[0.00] red health:[1.00]\n",
      " [41/50] [expert_system] ep_ret:[-102.5235] ep_len:[2124]. blue health:[0.00] red health:[1.00]\n",
      " [42/50] [zombie] ep_ret:[-2.9501] ep_len:[1123]. blue health:[0.00] red health:[1.00]\n",
      " [43/50] [rosie] ep_ret:[14.9786] ep_len:[3001]. blue health:[1.00] red health:[0.86]\n",
      " [44/50] [bud] ep_ret:[99.3348] ep_len:[1224]. blue health:[1.00] red health:[0.00]\n",
      " [45/50] [bud_fsm] ep_ret:[41.6227] ep_len:[3001]. blue health:[1.00] red health:[0.59]\n",
      " [46/50] [es_trial2] ep_ret:[0.7681] ep_len:[3001]. blue health:[1.00] red health:[1.00]\n",
      " [47/50] [es_trial3_scrimmage4] ep_ret:[-100.5663] ep_len:[792]. blue health:[0.00] red health:[1.00]\n",
      " [48/50] [expert_system] ep_ret:[-100.2660] ep_len:[489]. blue health:[0.00] red health:[1.00]\n",
      " [49/50] [zombie] ep_ret:[-4.5800] ep_len:[2565]. blue health:[0.00] red health:[1.00]\n",
      "[Eval. done] time:[day:[01] 00:09:44] ep_ret_avg:[10.419].\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[../data/net/ars_adt_cont/model_1.npz] saved.\n",
      "[1/5000] time:[day:[01] 00:16:49] max_ret:[50.82] max_ret_delta:[101.22] sigma_R:[33.61] \n",
      "[2/5000] time:[day:[01] 00:25:52] max_ret:[51.54] max_ret_delta:[101.70] sigma_R:[31.09] \n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "n_env_step = 0 # number of environment steps\n",
    "for t in range(int(total_steps)): # for all steps \n",
    "    esec = time.time()-start_time\n",
    "    \n",
    "    # Distribute the central weights to distributed workers\n",
    "    weights = R.get_weights() # weights of the central worker \n",
    "    noises_list = []\n",
    "    for _ in range(n_workers):\n",
    "        noises_list.append(get_noises_from_weights(weights,nu=nu))\n",
    "    \n",
    "    # Positive rollouts using distributed workers\n",
    "    set_weights_list = [worker.set_weights.remote(weights,noises,noise_sign=+1) \n",
    "                        for worker,noises in zip(workers,noises_list)] # set weights\n",
    "    rollout_ops = [worker.rollout.remote(\n",
    "        red_list=red_list_train\n",
    "    )\n",
    "           for worker in workers] # do positive rollouts\n",
    "    res_pos_rollout = ray.get(rollout_ops) # get positive rollout results\n",
    "    pos_rets,r_idx = np.zeros(n_workers),0\n",
    "    for pos_ret,ep_len,obs_buffer in res_pos_rollout:\n",
    "        pos_rets[r_idx] = pos_ret # return\n",
    "        r_idx = r_idx + 1\n",
    "        n_env_step += ep_len # accumulate episode length\n",
    "        for obs in obs_buffer: mv.include(obs) # update observation mean and std\n",
    "    \n",
    "    # Negative rollouts using distributed workers\n",
    "    set_weights_list = [worker.set_weights.remote(weights,noises,noise_sign=-1) \n",
    "                        for worker,noises in zip(workers,noises_list)] # set weights\n",
    "    rollout_ops = [worker.rollout.remote(\n",
    "        red_list=red_list_train\n",
    "    )\n",
    "           for worker in workers] # do negative rollouts\n",
    "    res_neg_rollout = ray.get(rollout_ops) # get negative rollout results\n",
    "    neg_rets,r_idx = np.zeros(n_workers),0\n",
    "    for neg_ret,ep_len,obs_buffer in res_neg_rollout:\n",
    "        neg_rets[r_idx] = neg_ret # return\n",
    "        r_idx = r_idx + 1\n",
    "        n_env_step += ep_len # accumulate episode length\n",
    "        for obs in obs_buffer: mv.include(obs) # update observation mean and std\n",
    "    \n",
    "    # Compute return statistics\n",
    "    concat_rets = np.concatenate((pos_rets,neg_rets)) # concatenated returns [2*n_workers]\n",
    "    ret_deltas = pos_rets - neg_rets # return difference [n_workers]\n",
    "    max_rets = np.maximum(pos_rets,neg_rets) # maximum returns [n_workers]\n",
    "    max_ret = np.max(max_rets) # maximum return [1]\n",
    "    max_ret_delta = np.max(np.abs(ret_deltas)) # maximum return diff [1]\n",
    "    sort_idx = np.argsort(-max_rets) # sort for resampling\n",
    "    \n",
    "    # Update\n",
    "    sigma_R = np.std(concat_rets)\n",
    "    weights_updated = []\n",
    "    for w_idx,weight in enumerate(weights): # for each weight \n",
    "        delta_weight_sum = np.zeros_like(weight)\n",
    "        for k in range(b):\n",
    "            idx_k = sort_idx[k] # sorted index\n",
    "            ret_delta_k,noises_k = ret_deltas[idx_k],noises_list[idx_k]\n",
    "            noise_k = (1/nu)*noises_k[w_idx] # noise for current weight\n",
    "            delta_weight_sum += ret_delta_k*noise_k\n",
    "        delta_weight = (alpha/(b*sigma_R))*delta_weight_sum\n",
    "        weight = weight + delta_weight\n",
    "        weights_updated.append(weight) \n",
    "    \n",
    "    # Set weights of the central worker \n",
    "    R.set_weights(weights_updated)\n",
    "    \n",
    "    # Distribute the central weights to the distributed workers\n",
    "    weights = R.get_weights() # get the updated weights from the central worker\n",
    "    zero_noises_list = []\n",
    "    for _ in range(n_workers):\n",
    "        zero_noises_list.append(get_noises_from_weights(weights,nu=0))\n",
    "    set_weights_list = [worker.set_weights.remote(weights,zero_noises,noise_sign=+1) \n",
    "                        for worker,zero_noises in zip(workers,zero_noises_list)] \n",
    "    \n",
    "    # Print\n",
    "    if (t == 0) or (((t+1)%print_every) == 0):\n",
    "        print (\"[%d/%d] time:[%s] max_ret:[%.2f] max_ret_delta:[%.2f] sigma_R:[%.2f] \"%\n",
    "               (t,total_steps,time.strftime(\"day:[%d] %H:%M:%S\", time.gmtime(time.time()-start_time)),\n",
    "               max_ret,max_ret_delta,sigma_R))\n",
    "        write_txt(f,\n",
    "                  \"[%d/%d] time:[%s] max_ret:[%.2f] max_ret_delta:[%.2f] sigma_R:[%.2f] \"%\n",
    "                  (t,total_steps,time.strftime(\"day:[%d] %H:%M:%S\", time.gmtime(time.time()-start_time)),\n",
    "                   max_ret,max_ret_delta,sigma_R),\n",
    "                  ADD_NEWLINE=True,DO_PRINT=False)\n",
    "    \n",
    "    # Evaluate\n",
    "    if (t == 0) or (((t+1)%evaluate_every) == 0): \n",
    "        ram_percent = psutil.virtual_memory().percent # memory usage\n",
    "        print (\"[Eval. start] step:[%d/%d][%.1f%%] #step:[%.1e] time:[%s] ram:[%.1f%%].\"%\n",
    "               (t+1,total_steps,t/total_steps*100,n_env_step,\n",
    "                time.strftime(\"day:[%d] %H:%M:%S\", time.gmtime(time.time()-start_time)),\n",
    "                ram_percent)\n",
    "              )\n",
    "        write_txt(f,\n",
    "                  \"[Eval. start] step:[%d/%d][%.1f%%] #step:[%.1e] time:[%s] ram:[%.1f%%].\"%\n",
    "                  (t+1,total_steps,t/total_steps*100,\n",
    "                   n_env_step,\n",
    "                   time.strftime(\"day:[%d] %H:%M:%S\", time.gmtime(time.time()-start_time)),\n",
    "                   ram_percent),\n",
    "                  ADD_NEWLINE=True,DO_PRINT=False)\n",
    "        ops = []\n",
    "        for i_idx in range(num_eval):\n",
    "            worker,red = workers[i_idx],red_list_eval[i_idx]\n",
    "            ops.append(worker.evaluate.remote(red=red))\n",
    "        eval_vals = ray.get(ops)\n",
    "        \n",
    "        ep_ret_sum = 0\n",
    "        for i_idx in range(num_eval):\n",
    "            red,eval_val = red_list_eval[i_idx],eval_vals[i_idx]\n",
    "            ep_ret,ep_len,blue_health,red_health = eval_val[0],eval_val[1],eval_val[2],eval_val[3]\n",
    "            ep_ret_sum += ep_ret\n",
    "            print (\" [%d/%d] [%s] ep_ret:[%.4f] ep_len:[%d]. blue health:[%.2f] red health:[%.2f]\"\n",
    "                %(i_idx,len(eval_vals),red,ep_ret,ep_len,blue_health,red_health))\n",
    "            write_txt(f,\n",
    "                      \" [%d/%d] [%s] ep_ret:[%.4f] ep_len:[%d]. blue health:[%.2f] red health:[%.2f]\"\n",
    "                      %(i_idx,len(eval_vals),red,ep_ret,ep_len,blue_health,red_health),\n",
    "                      ADD_NEWLINE=True,DO_PRINT=False)\n",
    "        ep_ret_avg = ep_ret_sum / num_eval\n",
    "        print (\"[Eval. done] time:[%s] ep_ret_avg:[%.3f].\\n\"%\n",
    "               (time.strftime(\"day:[%d] %H:%M:%S\", time.gmtime(time.time()-start_time)),\n",
    "                ep_ret_avg)\n",
    "              )\n",
    "        write_txt(f,\n",
    "                  \"[Eval. done] time:[%s] ep_ret_avg:[%.3f].\\n\"%\n",
    "                  (time.strftime(\"day:[%d] %H:%M:%S\", time.gmtime(time.time()-start_time)),\n",
    "                   ep_ret_avg),\n",
    "                  ADD_NEWLINE=True,DO_PRINT=False)\n",
    "        # Save\n",
    "        npz_path = '../data/net/%s/model_%d.npz'%(exp_name,t+1)\n",
    "        save_ars_model(npz_path,R,VERBOSE=False)\n",
    "        write_txt(f,\n",
    "                  \" [%s] saved.\"%npz_path,\n",
    "                  ADD_NEWLINE=True,DO_PRINT=False)\n",
    "        \n",
    "    # Distribute observation mean and std to workers (after evaluation)\n",
    "    obs_mean,obs_std = mv.mean,mv.std\n",
    "    sef_obs_list= [worker.set_observation_stats.remote(obs_mean,obs_std) \n",
    "                   for worker in workers] # set observation mean and std\n",
    "        \n",
    "    # Loop \n",
    "    # break # for debugging \n",
    "    \n",
    "print (\"Done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
